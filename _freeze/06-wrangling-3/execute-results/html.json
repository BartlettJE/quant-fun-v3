{
  "hash": "4a3f780127b0370782587008eca624a4",
  "result": {
    "engine": "knitr",
    "markdown": "# Data Wrangling 3: Pivots and Pipes {#06-wrangling-03}\n\n\n\n\n\nIn the last chapter, we looked at using one-table Wickham verbs to `filter`, `arrange`, `group_by`, `select`, `mutate` and `summarise` the pong data. We also learnt a little more about <a href='https://psyteachr.github.io/glossary/p#pipe' target='_blank' class='glossary' title='A way to order your code in a more readable format using the symbol %&gt;%'>pipes</a> and we saw how to do some quick counting and some ungrouping. Be sure to try out those activities before moving on as we will start to add a few more functions to allow us a few more skills in <a href='https://psyteachr.github.io/glossary/d#data-wrangling' target='_blank' class='glossary' title='The process of preparing data for visualisation and statistical analysis.'>data wrangling</a>. \n\nToday, as a progression from working with one table/tibble, we will focus on working with data across two or more tibbles To do this we are going to add two more functions, to the skills we already know. Those are:\n\n* `pivot_longer()` which allows us to **transform** a <a href='https://psyteachr.github.io/glossary/t#tibble' target='_blank' class='glossary' title='A container for tabular data with some different properties to a data frame'>tibble</a> from <a href='https://psyteachr.github.io/glossary/w#wide' target='_blank' class='glossary' title='A data format where all of the observations about one subject are in the same row'>wide</a> format to <a href='https://psyteachr.github.io/glossary/l#long' target='_blank' class='glossary' title='A data format where each observation is on a separate row'>long</a> format.\n\n* `inner_join()` which allows us to **combine** two tibbles together based on common columns. We actually saw this <a href='https://psyteachr.github.io/glossary/f#function' target='_blank' class='glossary' title='A named section of code that can be reused.'>function</a> in Chapter 3 so this might be more of a recap.\n\nAnd just to recap, if you are still struggling with the idea of a function, remember that a function takes an input, performs some action, and gives an output. Think of your toaster again like we mentioned before: it takes bread as an input; it performs the action of heating it up; and it gives an output, the toast. A good thing about a lot of the functions we use is that they are nicely named as verbs to describe what they do - `mutate()` mutates (adds on a column); `arrange()` arranges columns, `summarise()` summarises, etc. But keep in mind that you don't have to know or memorise all the different functions; through practice and repetition you will quickly learn to remember which ones are which and what <a href='https://psyteachr.github.io/glossary/p#package' target='_blank' class='glossary' title='A group of R functions.'>package</a> they come from. Sort of like where to find your spoons in your kitchen - you don't look in the fridge, and then the washing machine, and then the drawer. Nope, you learnt, by repetition, to look in the drawer first time. It's the same with functions. Keep in mind that research methods is like a language in that the more you use it and work with it the more it makes sense. So with that, let's do some practicing! \n\n**Chapter Intended Learning Outcomes (ILOs)**\n\nBy the end of this chapter, you will be able to: \n\n- ILO1\n\n## Chapter preparation\n\n### Introduction to the data set \n\nFor this chapter, we are using open data from @alter_vssl_2024. The abstract of their article is:\n\n> The biggest difference in statistical training from previous decades is the increased use of software. However, little research examines how software impacts learning statistics. Assessing the value of software to statistical learning demands appropriate, valid, and reliable measures. The present study expands the arsenal of tools by reporting on the psychometric properties of the Value of Software to Statistical Learning (VSSL) scale in an undergraduate student sample. We propose a brief measure with strong psychometric support to assess students' perceived value of software in an educational setting. We provide data from a course using SPSS, given its wide use and popularity in the social sciences. However, the VSSL is adaptable to any statistical software, and we provide instructions for customizing it to suit alternative packages. Recommendations for administering, scoring, and interpreting the VSSL are provided to aid statistics instructors and education researchers understand how software influences students' statistical learning.\n\nTo summarise, they developed a new scale to measure students' perceived value of software to learning statistics - Value of Software to Statistical Learning (VSSL). The authors wanted to develop this scale in a way that could be adapted to different software, from SPSS in their article (which some of you may have used in the past), to perhaps R in future. Alongside data from their new scale, they collected data from other scales measuring a similar kind of construct (e.g., Students' Attitudes toward Statistics and Technology) and related constructs (e.g., Quantitative Attitudes). \n\nIn this chapter, we will wrangle their data to reinforce skills from Chapter 4 and 5. Scale data is extremely common to work with in psychology and there is a high likelihood you will use one or more in your dissertation or future careers. After recapping skills from the past two chapters on this new data set, we will add more data wrangling functions to your toolkit. \n\n### Organising your files and project for the chapter\n\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\n1. In your folder for research methods and the book `ResearchMethods1_2/Quant_Fundamentals`, you should have a folder from chapter 4 called `Chapter_04_06_datawrangling`.\n\n2. Create a new R Markdown document and give it a sensible title describing the chapter, such as `06 Data Wrangling 3`. Delete everything below line 10 so you have a blank file to work with and save the file in your `Chapter_04_06_datawrangling` folder. \n\n4. We are working with a new data set separated into two files. The links are data file one ([Alter_2024_demographics.csv](data/Alter_2024_demographics.csv)) and data file two ([Alter_2024_scales.csv](data/Alter_2024_scales.csv)). Right click the links and select \"save link as\", or clicking the links will save the files to your Downloads. Make sure that both files are saved as \".csv\". Save or copy the file to your `data/` folder within `Chapter_04_06_datawrangling`.\n\nYou are now ready to start working on the chapter! \n\n## Recapping all the previous <pkg>dplyr</pkg> functions\n\nIn this first section, we will prepare the data for some analysis later by practicing the data wrangling skills you learnt in Chapters 4 and 5 on this new data set. \n\n### Activity 1 - Load <pkg>tidyverse</pkg> and read the data files\n\nAs the first activity, load <pkg>tidyverse</pkg> and read the two data files. As a prompt, save the data files to these object names to be consistent with the activities below, but you can check your answer below if you are stuck. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the tidyverse package below\n?\n\n# Load the data files\n# This should be the Alter_2024_demographics.csv file \ndemog <- ?\n\n# This should be the Alter_2024_scales.csv file \nscales <- ?\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Alter_2024_demographics.csv file \ndemog <- read_csv(\"data/Alter_2024_demographics.csv\")\n\n# This should be the Alter_2024_scales.csv file \nscales <- read_csv(\"data/Alter_2024_scales.csv\")\n```\n:::\n\n\n:::\n\n### Activity 2 - Explore `demog` and `scales`\n\nThe data from @alter_vssl_2024 is split into two data files. In `demog`, we have the participant ID (`StudentIDE`) and several demographic variables. The columns (variables) we have in the data set are:\n\n| Variable       |       Type                       |           Description          |\n|:--------------:|:---------------------------------|:-------------------------------|\n| StudentIDE    | double| Participant number             |\n| GenderE    | double| Gender: 1 = Female, 2 = Male, 3 = Non-Binary |\n| RaceEthE    | double| Ethnicity: 1 = Black/African American, 2 = Hispanic/Other Latinx, 3 = White, 4 = Multiracial, 5 = Asian/Pacific Islander, 6 = Native American/Alaska Native, 7 = South/Central American |\n| GradeE    | character| Expected grade: 1 = A,\t2 = B,\t3 = C, 4 = D,\t5 = F |\n| StuStaE    | character| Student status: 1 = Freshman, 2 = Sophomore,\t3 = Junior,\t4 = Senior or Higher |\n| GPAE    | character| Expected Grade Point Average (GPA) |\n| MajorE    | character| Degree major |\n| AgeE    | double| Age in years |\n\nIn `scales`, we then have the participant ID (`StudentIDE`) and all the individual scale items. The columns (variables) we have in the data set are:\n\n| Variable       |       Type                       |           Description          |\n|:--------------:|:---------------------------------|:-------------------------------|\n| StudentIDE    | double| Participant number             |\n| MA1E to MA8E    | double| **Enjoyment of Mathematics and statistics**, not analysed in this study. |\n| QANX1E to QANX4E    | double| **Quantitative anxiety**: four items scored on a 5-point Likert scale ranging from 1 (Not at all Anxious) to 5 (Extremely Anxious) |\n| QINFL1E to QINFL7E    | double| **Quantitative attitudes**: seven items scored on a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree) |\n| QSF1E to QSF4E    | double| **Study motivation**, not analysed in this study. |\n| QHIND1E to QHIND5E    | double| **Quantitative hindrances**: five items scored on a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree) |\n| QSC1E to QSC4E    | double| **Mathematical self-efficacy**, not analysed in this study. |\n| QSE1E to QSE6E    | double| **Mathematical ability**, not analysed in this study. |\n| SPSS1E to SPSS10E    | double| **VSSL scale on SPSS**: 10 items scored on a 5-point Likert scale ranging from 1 (Never True) to 5 (Always True) |\n\n::: {.callout-tip}\n#### Try this\nNow we have introduced the two data sets, explore them using different methods we introduced. For example, opening the data objects as a tab to scroll around, explore with `glimpse()`, or even try plotting some of the variables to see what they look like using visualisation skills from Chapter 3. \n:::\n\n### Activity 3 - Joining the two data sets using `inner_join()`\n\nAt the moment, we have two separate data sets, but it will make things easier to join them together so we have both demographic information and the participants' responses to the scales. \n\nWe did not recap joining data sets in the last chapter, so you might need to revisit Chapter 4 - [Joining two data frames](#04-joins)  - for a recap. \n\nCreate a new data object called `full_data` and see if you can spot a common variable between both data sets that you can use an identifier. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# join demog and scales by a common identifier \nfull_data <- ?\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# join demog and scales by a common identifier \nfull_data <- inner_join(x = demog,\n                        y = scales,\n                        by = \"StudentIDE\")\n```\n:::\n\n:::\n\n### Activity 4 - Selecting a range of columns using `select()`\n\nThere are some scales in the data that @alter_vssl_2024 did not analyse, so we can get rid of them to declutter. Furthermore, the purpose of their study was to validate the new VSSL scale and they found some items did not make the cut. Create a new object called `full_data_select` and **retain** the following variables from your new `full_data` object:\n\n- `StudentIDE`\n\n- `GenderE`\n\n- `RaceEthE`\n\n- `AgeE` \n\n- `QANX1E` to `QINFL7E`\n\n- `QHIND1E` to `QHIND5E`\n\n- `SPSS1E`, `SPSS4E`, `SPSS5E`, `SPSS6E`, `SPSS7E`, `SPSS8E`, `SPSS9E`. \n\nRemember: you can select variables either by **retaining** the variables you want to keep, or **removing** the variables you want to remove. You should have **27** columns remaining. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# select the key variables listed above\nfull_data_select <- ?\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk if you chose to retain: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# select the key variables listed above\nfull_data_select <- select(full_data,\n                           StudentIDE, \n                           GenderE,\n                           RaceEthE, \n                           AgeE, \n                           QANX1E:QINFL7E, \n                           QHIND1E:QHIND5E, \n                           SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E)\n```\n:::\n\n\nor the following if you chose to remove: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# select the key variables listed above\nfull_data_select <- select(full_data,\n                           -GradeE, \n                           -StuStaE, \n                           -GPAE, \n                           -MajorE, \n                           -MA1E:-MA8E,\n                           -QSF1E:-QSF4E,\n                           -QSC1E:-QSE6E,\n                           -SPSS2E, -SPSS3E, -SPSS10E)\n```\n:::\n\n:::\n\n### Activity 5 - Reorder observations using `arrange()` \n\nFor a quick check of the data, order the values of `AgeE` using the object `full_data_select` and answer the following questions:\n\n1. The youngest participant is <input class='webex-solveme nospaces' size='2' data-answer='[\"18\"]'/> years old. \n\n2. The old participant is <input class='webex-solveme nospaces' size='2' data-answer='[\"39\"]'/> years old. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# youngest participants\narrange(?)\n\n# oldest participants\narrange(?)\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# youngest participants\narrange(full_data_select, \n        AgeE)\n\n# oldest participants\narrange(full_data_select, \n        desc(AgeE))\n```\n:::\n\n:::\n\n### Activity 6 - Modifying or creating variables using `mutate()`\n\nAt the moment, we have categorical variables such gender (`GenderE`) and race (`RaceEthE`) which have numerical codes. When it comes to summarising or plotting later, this would not be the easiest to understand. \n\nUsing the `full_data_select` object, use `mutate()` to recode these two existing variables and replace the numbers with labels and create a new object `full_data_mutate`. As a reminder of what each number refers to: \n\n`GenderE`\n\n- 1 = Female\n\n- 2 = Male\n\n- 3 = Non-Binary\n\n`RaceEthE`\n\n- 1 = Black/African American\n\n- 2 = Hispanic/Other Latinx\n\n- 3 = White\n\n- 4 = Multiracial\n\n- 5 = Asian/Pacific Islander\n\n- 6 = Native American/Alaska Native\n\n- 7 = South/Central American\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# recode gender and race to labels\nfull_data_mutate <- mutate(full_data_select,\n                           GenderE = ?,\n                           RaceEthE = ?)\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk (some lines wrap due to being quite long, but it will look right if you copy and paste it to your RStudio): \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# recode gender and race to labels\nfull_data_mutate <- mutate(full_data_select,\n                           GenderE = case_match(GenderE,\n                                                1 ~ \"Female\",\n                                                2 ~ \"Male\",\n                                                3 ~ \"Non-binary\"),\n                           RaceEthE = case_match(RaceEthE,\n                                                 1 ~ \"Black/African American\",\n                                                 2 ~ \"Hispanic/Other Latinx\",\n                                                 3 ~ \"White\",\n                                                 4 ~ \"Multiracial\",\n                                                 5 ~ \"Asian/Pacific Islander\",\n                                                 6 ~ \"Native American/Alaska Native\",\n                                                 7 ~ \"South/Central American\"))\n```\n:::\n\n:::\n\n#### Bonus activity - reverse coding scales {#06-reverse-coding}\n\nFor a bonus activity, we want to demonstrate a super common task when working with scale data. Often, scales will **<a class='glossary' title='Having two similar questions, one expressed in a positive way, and another expressed in a negative way.'>reverse code</a>** some items to express the same idea in opposite ways: one positive and one negative. If the scale is measuring a consistent construct, the responses should be more positive in one and more negative in the other. If you analysed this immediately, you would get two opposing answers, so a key data analysis step is reverse coding some items so all the numbers mean a similar thing. \n\nIn @alter_vssl_2024, all the VSSL items we removed were reverse coded, but it is a good excuse to practice. Using the `scales` object, what function could you use to recode existing responses? Hint: we want to recode 1 to 5, 2 to 4, etc. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# recode items 2, 3, and 10\nscales_reverse <- mutate(scales,\n                         SPSS2_R = ?,\n                         SPSS3_R = ?,\n                         SPSS10_R = ?)\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nBased on what we covered before, we expect you will have completed a perfectly accurate but long process of recoding each item one by one: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# recode items 2, 3, and 10\nscales_reverse <- mutate(scales,\n                         SPSS2_R = case_match(SPSS2E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1),\n                         SPSS3_R = case_match(SPSS3E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1),\n                         SPSS10_R = case_match(SPSS10E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1))\n```\n:::\n\n\nHowever, there is a neat shortcut where you can subtract the response from the biggest scale unit plus 1. For example, if you have a 5-point scale, you would subtract the response from 6, if you have a 7-point scale, from 8 etc. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Reverse code by subtracting responses from 6\nscales_reverse <- mutate(scales,\n                         SPSS2_R = 6 - SPSS2E,\n                         SPSS3_R = 6 - SPSS3E,\n                         SPSS10_R = 6 - SPSS10E)\n```\n:::\n\n\nExplore your new data object to see what the new reverse coded variables look like. \n:::\n\n### Activity 7 - Removing or retaining observations using `filter()`\n\nTo practice filtering data to retain specific participants, imagine we wanted to focus on two specific groups of people. \n\nFirst, we just want to explore the data of non-binary participants. Second, we want to explore the data of female, Asian/Pacific Islander participants. Use `filter()` on the `full_data_mutate` object to create two objects: `NB_participants` and `F_asian_participants`. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# non-binary participants\nNB_participants <- ?\n\n# female, Asian/Pacific Islander participants\nF_asian_participants <- ?\n```\n:::\n\n\nAfter creating the objects, answer the following questions: \n\n1. We have <input class='webex-solveme nospaces' size='1' data-answer='[\"1\"]'/> non-binary participant(s) in the data set.  \n\n2. We have <input class='webex-solveme nospaces' size='1' data-answer='[\"9\"]'/> female, Asian/Pacific Islander participant(s) in the data set.\n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# non-binary participants\nNB_participants <- filter(full_data_mutate,\n                          GenderE == \"Non-binary\")\n\n# female, Asian/Pacific Islander participants\nF_asian_participants <- filter(full_data_mutate,\n                          GenderE == \"Female\",\n                          RaceEthE == \"Asian/Pacific Islander\")\n```\n:::\n\n:::\n\n#### Bonus activity - Removing NAs with `drop_na()` {#06-drop-NAs}\n\nOne concept we will spend more time on in Chapter 11 - Screening Data - is removing participants who do not provide an answer. We delve more into the decision making in the course materials, but there is a handy function in <pkg>tidyr</pkg> called `drop_na()`. You could do this using filter, but the standalone function streamlines things. If you run the function on your whole data set, it will remove observations with one or more NAs in all their variables: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# remove observations with any NAs\nno_NAs <- drop_na(full_data_mutate)\n```\n:::\n\n\nHowever, often you do not want to remove all variables with an NA as there might be valuable information elsewhere. You can add one or more variables to ask `drop_na()` to only remove NAs present in those specific variables: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# remove observations with any NAs\nage_NAs <- drop_na(full_data_mutate,\n                   AgeE)\n```\n:::\n\n\nThis impacts the number of participants we remove as we had 171 when we removed all NAs, but 179 when we only removed NAs in age. \n\n### Activity 8 - Summarising data using `count()` and `summarise()`\n\n#### Counting observations\n\nAs the final recap activity, it is time to calculate some summary statistics to understand our data set. First, use `count()` on the `full_data_mutate` object to answer the following questions: \n\n1. How many observations do we have of each gender? <input class='webex-solveme nospaces' size='2' data-answer='[\"29\"]'/> males, <input class='webex-solveme nospaces' size='3' data-answer='[\"149\"]'/> females, and <input class='webex-solveme nospaces' size='1' data-answer='[\"1\"]'/> non-binary. \n\n2. How many observations do we have of each race? <input class='webex-solveme nospaces' size='3' data-answer='[\"131\"]'/> white, <input class='webex-solveme nospaces' size='2' data-answer='[\"13\"]'/> Black/African American, and <input class='webex-solveme nospaces' size='1' data-answer='[\"1\"]'/> NA with missing data. \n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# count each group in GenderE\ncount(full_data_mutate,\n      GenderE)\n\n# count each group in RaceE\ncount(full_data_mutate,\n      RaceEthE)\n```\n:::\n\n:::\n\n#### Summarising observations\n\nOne useful demographic summary is the mean and standard deviation (*SD*) of participant ages. We have covered the function for the mean (`mean()`) several times, but a key part of coding is knowing what you want, but not the function to do it. So, in the process of the next answer, try and find the function for the standard deviation on your own. If you are really stuck though, you can see the hint below. \n\n::: {.callout-note collapse=\"true\"}\n#### Give me a hint for the SD function\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Function for the standard deviation\nsd()\n```\n:::\n\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Mean and SD age\nmean_age <- summarise(full_data_mutate,\n                      mean_age = ?,\n                      SD_age = ?)\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Mean and SD age\nmean_age <- summarise(full_data_mutate,\n                      mean_age = mean(AgeE, na.rm = TRUE),\n                      SD_age = sd(AgeE, na.rm = TRUE))\n```\n:::\n\n\nRemember, if there are NAs present in the data like this, you need to add `na.rm = TRUE` or handle NAs prior to applying the function. \n:::\n\n::: {.callout-important}\n#### Error mode\n\nAs a transition point to restructuring data, imagine we wanted to calculate the sum score of the items to calculate a number for the whole scale. Based on how we have used `mutate()` or `summarise()` before, you might try:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsum_VSSL <- mutate(full_data_mutate,\n                      VSSL = sum(c(SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E), na.rm = TRUE))\n```\n:::\n\n\nHowever, if you look at the object, the VSSL column is the same for every participant (4413) which does not look right? This is due to how functions work within `mutate()`. It is essentially applying the `sum()` function to all the columns first and adding them together, rather than summing the values of each column within each participant. \n\nWe can fix this problem by restructuring the data. \n:::\n\n## Restructuring data using `pivot_longer()` and `pivot_wider()`\n\nApart from joining two data sets, we have pretty much just worked with the data files as they come to us where each row represents one observation/participant and each column represents one variable. That is great but there are scenarios where you get data sets in messier formats that do not follow this pattern. Furthermore, you might need to restructure your data to perform certain functions, like taking the mean/sum of many columns per participant or visualising multiple elements. Before we work on the data wrangling side, we need a brief explanation of data formats. \n\n### Tidy data \n\nFor most of this book, we will use a type of data organisation known as <a href='https://psyteachr.github.io/glossary/t#tidy-data' target='_blank' class='glossary' title='A format for data that maps the meaning onto the structure.'>tidy data</a>. Any data in this format is easily processed through the `tidyverse` family of packages. However, the data you work with will not always start formatted in the most efficient way possible. If that happens then our first step is to put it into a tidy data format. There are two fundamental principles defining tidy data:\n\n1. Each variable must have its own column.\n\n2. Each observation must have its own row.\n\n@wickham_tidy_2014 adds the following principle:\n\n3. Each type of observation unit forms a table. \n\n[Grolemund and Wickham (2023)](https://r4ds.hadley.nz/data-tidy.html){target=\"_blank\"} restate this third principle as: \"Each value must have its own cell (i.e. no grouping two variables together, e.g. time/date in one cell)\" where a cell is where any specific row and column meet. A single data point in a data frame / tibble is a cell for example. The Grolemund and Wickham (2023) book is a very useful source for further reading and it is free, but browsing the chapter on tidy data will help you visualise how you want to arrange data.\n\n::: {.callout-note}\nIf you have worked with any kind of data before, particularly if you have used Excel, it is likely that you will have used **wide format** or **long format** data. In wide format, each participant's data is all in one row with multiple columns for different data points. This means that the data set tends to be very wide and you will have as many rows as you have participants. \n\nLong format is where each **row** is a single observation, typically a single trial in an experiment or a response to a single item on a questionnaire. When you have multiple trials per participant, you will have multiple rows for the same participant. To identify participants, you would need a variable with some kind of participant id, which can be as simple as a distinct integer value for each participant. In addition to the participant identifier, you would have any measurements taken during each observation (e.g., response time) and what experimental condition the observation was taken under.\n\nIn wide format data, each **row** corresponds to a single participant, with multiple observations for that participant spread across columns. So for instance, with survey data, you would have a separate column for each survey question.\n\nTidy data is a mix of both of these approaches and most functions in the `tidyverse` assume the tidy format, so typically the first thing you need to do when you get data is think about what format you need your data to perform the functions and analyses you want.\n:::\n\n### Activity 9: Gathering with `pivot_longer()`\n\nIn it's current format, we have wide data where each row is a separate participant and each column is a separate variable. We can use the function <a class='glossary' title='Gather data by increasing the number of rows and decreasing the number of columns.'>pivot_longer()</a> from the <pkg>tidyr</pkg> package within `tidyverse`. \n\nThe pivot functions can be easier to show than explain first, so type and run the following code using the `full_data_mutate` object:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfull_data_long <- pivot_longer(data = full_data_mutate,\n                      cols = SPSS1E:SPSS9E,\n                      names_to = \"Question\", \n                      values_to = \"Response\")\n```\n:::\n\n\nTo break down the code:\n\n- We create a new data object called `full_data_long` by applying the `pivot_longer()` function to `full_data_mutate`. \n\n- In the `cols` argument, we specify the columns we want to gather. We use the colon method here like `select()` to choose the 7 columns for the VSSL items. If the columns are not in order, you could use the `c()` method instead (e.g., `cols = c(SPSS1E, SPSS9E)`). \n\n- The `names_to` argument is what your first new column will be called. All the column names you selected in `cols` will be pivoted into this new column, so call it something sensible you will remember later. Here, we call the new column \"Question\". \n\n- The `values_to` argument is what your second new column will be called. For all the columns you gather, the response of each participant will be in one column stacked on top of each other next to its label in \"Question\". You also need to call this something memorable, like \"Response\" here. \n\nNow, explore the new `full_data_long` object you just created and compare it to `full_data_mutate`. Instead of 181 rows, we now have 1267 rows. Instead of 27 variables, we now have 22 variables. We have 181 participants who responded to 7 VSSL items, so we pivot the data into long format to get 181 * 7 = 1267 rows. \n\nVisually, you can see the difference with a preview of just the participant ID and VSSL items here: \n\n::: {.panel-tabset}\n#### Original wide format\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| StudentIDE| SPSS1E| SPSS4E| SPSS5E| SPSS6E| SPSS7E| SPSS8E| SPSS9E|\n|----------:|------:|------:|------:|------:|------:|------:|------:|\n|          1|      4|      3|      3|      3|      4|      4|      4|\n|          2|      4|      4|      4|      4|      4|      4|      4|\n|          3|      3|      2|      3|      2|      2|      3|      3|\n|          4|      2|      2|      2|      2|      2|      2|      2|\n|          5|      4|      3|      4|      4|      3|      4|      3|\n|          6|      2|      3|      2|      1|      3|      3|      3|\n|          7|      4|      2|      4|      4|      2|      3|      2|\n|          8|      2|      3|      3|      3|      3|      3|      2|\n|          9|      3|      3|      3|      1|      4|      3|      2|\n|         10|      4|      4|      3|      5|      4|      2|      4|\n\n</div>\n:::\n:::\n\n\n#### New long format\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| StudentIDE|Question | Response|\n|----------:|:--------|--------:|\n|          1|SPSS1E   |        4|\n|          1|SPSS4E   |        3|\n|          1|SPSS5E   |        3|\n|          1|SPSS6E   |        3|\n|          1|SPSS7E   |        4|\n|          1|SPSS8E   |        4|\n|          1|SPSS9E   |        4|\n|          2|SPSS1E   |        4|\n|          2|SPSS4E   |        4|\n|          2|SPSS5E   |        4|\n\n</div>\n:::\n:::\n\n:::\n\nNow we have our data in long form, we can calculate summary statistics for participants using `group_by()` and `summarise()`. First, we group the data by the participant ID, as we want one value per participant:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# group full_data_long by StudentIDE\nlongdata_grouped <- group_by(full_data_long, \n                             StudentIDE)\n```\n:::\n\n\nSecond, we create a new variable using `summarise()` to take the sum of all the items. This will create the VSSL scale score consistent with @alter_vssl_2024: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calculate the sum of VSSL items by taking the sum of Response\nVSSL_sum <- summarise(longdata_grouped,\n                      VSSL_sum = sum(Response))\n```\n:::\n\n\nOur new object goes from 1267 rows back to 181 as we grouped by the participant ID and took the sum of `Response`. This means we apply the function we provide `summarise()` to all the rows we want to group by, in this case across all 7 VSSL items. Your new object has just two columns: `StudentIDE` and `VSSL_sum`. \n\nAt this point, you could join the object to `full_data_mutate` to add the scale score to all the other variables, but we will come back to that when we cover pipes. \n\n::: {.callout-tip}\n#### Try this\n\nWe calculated the VSSL scale score by pivoting longer, grouping the data, and taking the sum of the 7 items. To test your understanding, complete the same steps to calculate the scale score of **Quantitative anxiety** using the four columns `QANX1E` to `QANX4E`. The scale score here also involves taking the sum of the columns. Use the `full_data_mutate` object as your starting point for the data. \n\nCheck your attempt with the solution below when you have tried on your own. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# gather the four quant anxiety items to long form\nquant_anxiety_long <- ?\n\n# group the long data by participant ID\nquant_anxiety_group <- ?\n\n# calculate the sum quant anxiety per participant\nsum_quant_anxiety <- ?\n```\n:::\n\n\nTo check your answers: \n\n1. Participant 1 has a sum quantitative anxiety score of  <input class='webex-solveme nospaces' size='1' data-answer='[\"6\"]'/>\n\n2. Participant 5 has a sum quantitative anxiety score of  <input class='webex-solveme nospaces' size='2' data-answer='[\"16\"]'/>\n\n:::\n\n::: {.callout-caution collapse=\"true\"} \n#### Solution\n\nWe complete the task in three steps. First, we pivot longer using the four columns QANX1E to QANX4E to create the new `quant_anxiety_long` object. Second, we group that new long data object by the participant ID. Third, we calculate the sum quantitative anxiety score by taking the sum of the responses per participant ID. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# gather the four quant anxiety items to long form\nquant_anxiety_long <- pivot_longer(data = full_data_mutate,\n                                   cols = QANX1E:QANX4E,\n                                   names_to = \"Question\",\n                                   values_to = \"Response\")\n\n# group the long data by participant ID\nquant_anxiety_group <- group_by(quant_anxiety_long, \n                                StudentIDE)\n\n# calculate the sum quant anxiety per participant\nsum_quant_anxiety <- summarise(quant_anxiety_group,\n                               sum_quant_anxiety = sum(Response))\n```\n:::\n\n\n:::\n\n### Spreading with `pivot_wider()`\n\nYou might also find yourself in situations where you must restructure data in the opposite direction: from long to wide. There is a complementary function called `pivot_wider()` where you can spread values from one column to multiple columns. You need two columns in your long form data set, one for the variable names which will be your column names, then one for the responses which will be the values in each cell. \n\nTo demonstrate this function, we will transform `full_data_long` back to wide format so we have 7 columns of VSSL items: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfull_data_wide <- pivot_wider(data = full_data_long,\n                              names_from = \"Question\",\n                              values_from = \"Response\")\n```\n:::\n\n\nTo break down the code: \n\n- We create a new object `full_data_wide` by applying the function `pivot_wider()` to `full_data_long`.\n\n- In the `names_from` argument, we add the column name which contains the names of the variables you want as your new column names. \n\n- In the `values_from` argument, we add the column name which contains the values of the variables which will be the cells of your data frame. \n\nThe new object `full_data_wide` should now look exactly the same as the `full_data_mutate` object we started with. \n\n::: {.callout-note}\n#### Do I need to add quotes to the column names?\n\nYou might have noticed we added quotes around the column names to specify the `names_from` and `values_from` arguments. When we specify columns in `tidyverse` functions, we do not need to add the quotes, we can just type the name and it will work (`names_from = \"Question\"` and `names_from = Question` would both work here). However, in other functions outside the `tidyverse`, you normally need to add the quotes around column names. When to add quotes or not can take a while to get used to, so this is just a note to highlight you might try one method and it does not work, but you can try the other method instead. \n:::\n\n::: {.callout-tip}\n#### Try this\n\nIn the `pivot_longer()` section, you should have created a new object `quant_anxiety_long` if you completed the \"Try this\" activity. To test your understanding of `pivot_wider()`, spread the four items and responses of **Quantitative anxiety** back to wide format. Use the `quant_anxiety_long` object as your starting point and create a new object called `quant_anxiety_wide`. \n\nCheck your attempt with the solution below when you have tried on your own. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# spread the quant anxiety items back to wide form\nquant_anxiety_wide <- ?\n```\n:::\n\n\n:::\n\n::: {.callout-caution collapse=\"true\"} \n#### Solution\n\nThis task follows the exact format as `full_data_wide` if you named your variables the same as ours. It is just important the `names_from` and `values_from` columns are the same as those you used in `quant_anxiety_long`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# spread the quant anxiety items back to wide form\nquant_anxiety_wide <- pivot_wider(quant_anxiety_long, \n                                  names_from = \"Question\",\n                                  values_from = \"Response\")\n```\n:::\n\n\n:::\n\n## Combining several functions with pipes \n\nIn this final section on data wrangling, we are not covering new functions, but a new way of working. So far, we have created lots of new objects by applying individual `tidyverse` functions, but there is a way to string together several functions and streamline your code. We wanted to introduce you to the individual functions first to develop your fundamentals skills and understanding of what the functions do, but now we can be a little more efficient.  \n\nInstead of creating several objects, you can use <a href='https://psyteachr.github.io/glossary/p#pipe' target='_blank' class='glossary' title='A way to order your code in a more readable format using the symbol %&gt;%'>pipes</a>. We write pipes as `%>%` and you can be read them as \"and then\". Pipes allow you to string together 'sentences' of code into 'paragraphs' so that you do not need to create intermediary objects. \n\nThis is one of those concepts that is initially easier to show than tell: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create an object starting with demog \nfull_data_pipe <-  demog %>%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %>%\n  # Select key columns\n  select(StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E) %>% \n  # Recode variables with labels\n  mutate(GenderE = case_match(GenderE,\n                              1 ~ \"Female\",\n                              2 ~ \"Male\",\n                              3 ~ \"Non-binary\"),\n         RaceEthE = case_match(RaceEthE,\n                               1 ~ \"Black/African American\",\n                               2 ~ \"Hispanic/Other Latinx\",\n                               3 ~ \"White\",\n                               4 ~ \"Multiracial\",\n                               5 ~ \"Asian/Pacific Islander\",\n                               6 ~ \"Native American/Alaska Native\",\n                               7 ~ \"South/Central American\"))\n```\n:::\n\n\nInstead of creating all the intermediary objects, we go straight from joining the two data sets to recoding the variables in mutate, all in one object. Side by side, you can see the difference in the process we had to go through: \n\n::: {.panel-tabset}\n#### Creating separate objects\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# join demog and scales by a common identifier \nfull_data <- inner_join(x = demog,\n                        y = scales,\n                        by = \"StudentIDE\")\n\n# select the key variables listed above\nfull_data_select <- select(full_data,\n                           StudentIDE, \n                           GenderE,\n                           RaceEthE, \n                           AgeE, \n                           QANX1E:QINFL7E, \n                           QHIND1E:QHIND5E, \n                           SPSS1E, SPSS4E:SPSS9E)\n\n# recode gender and race to labels\nfull_data_mutate <- mutate(full_data_select,\n                           GenderE = case_match(GenderE,\n                                                1 ~ \"Female\",\n                                                2 ~ \"Male\",\n                                                3 ~ \"Non-binary\"),\n                           RaceEthE = case_match(RaceEthE,\n                                                 1 ~ \"Black...\",\n                                                 2 ~ \"Hispanic...\",\n                                                 3 ~ \"White\",\n                                                 4 ~ \"Multiracial\",\n                                                 5 ~ \"Asian...\",\n                                                 6 ~ \"Native American...\",\n                                                 7 ~ \"South...\"))\n```\n:::\n\n\n#### Combining functions using pipes\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create an object starting with demog \nfull_data_pipe <-  demog %>%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %>%\n  # Select key columns\n  select(StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E:SPSS9E) %>% \n  # Recode variables with labels\n  mutate(GenderE = case_match(GenderE,\n                              1 ~ \"Female\",\n                              2 ~ \"Male\",\n                              3 ~ \"Non-binary\"),\n         RaceEthE = case_match(RaceEthE,\n                               1 ~ \"Black...\",\n                               2 ~ \"Hispanic...\",\n                               3 ~ \"White\",\n                               4 ~ \"Multiracial\",\n                               5 ~ \"Asian...\",\n                               6 ~ \"Native American...\",\n                               7 ~ \"South...\"))\n```\n:::\n\n:::\n\nAs you get used to using pipes, remember you can interpret them as \"and then\". So, we could explain the function of the code to ourselves as: \n\n- Create `full_data_pipe` by starting with `demog` data, **and then**\n\n- Join with the `scales` data using `StudentIDE` as an identifier, **and then**,\n\n- Select our key columns, **and then**\n\n- Mutate to recode gender and race.\n\nIt can be tricky at first to understand what pipes are doing from a conceptual point of view, but it is well worth learning to use them. When your code starts getting longer, they are much more efficient and you write less code which is always a good thing to debug and find errors. You also have fewer objects in your environment as we created one object instead of three, tidying your workspace. \n\n::: {.callout-important}\n#### Error mode\n\nOne key difference that can trip people up is we no longer specify the data object as the first argument in each function. The reason that this function, the `%>%`, is called a pipe is because it 'pipes' the data through to the next function. When you wrote the code previously, the first argument of each function was the dataset you wanted to work on. When you use pipes, it will automatically take the data from the previous line of code so you do not need to specify it again. \n\nFor example, if we tried to specify `demog` again in `select()`, we would just receive an error.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create an object starting with demog \nfull_data_pipe <-  demog %>%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %>%\n  # Select key columns\n  select(.data = demog,\n         StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E:SPSS9E)\n```\n:::\n\n\n:::\n\n::: {.callout-tip}\n#### Try this\n\nPipes also work with other functions like `filter()`, `group_by()` and `summarise()`. If you start with the object `full_data_mutate`, try and express the following instructions in code: \n\n1. Create a new object `age_groups` using `full_data_mutate` as your starting point, **and then** \n\n2. Filter to only include \"White\" and \"Black/African American\" participants using `RaceEthE`, **and then**,\n\n3. Group the observations by `RaceEthE`, **and then**,\n\n4. Summarise the data to calculate the mean and standard deviation `AgeE`. \n\nCheck your attempt with the solution below when you have tried on your own. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# create age_groups by filtering, grouping, and summarising\nage_groups <- full_data_mutate %>% \n  ?\n```\n:::\n\n\n:::\n\n::: {.callout-caution collapse=\"true\"} \n#### Solution\n\nWe complete this task in three steps. First, we filter `full_data_mutate` to just focus on White and Black/African American participants. Second, we group the data by `RaceEthE` so our summary statistics are split into two groups. Third, we calculate the mean and SD age.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# create age_groups by filtering, grouping, and summarising\nage_groups <- full_data_mutate %>% \n  filter(RaceEthE %in% c(\"White\", \"Black/African American\")) %>% \n  group_by(RaceEthE) %>% \n  summarise(mean_age = mean(AgeE, na.rm = TRUE),\n            SD_age = sd(AgeE, na.rm = TRUE))\n```\n:::\n\n\n:::\n\n## Test yourself\n\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter. \n\n### Knowledge check\n\n* Complete the sentence, the higher the AQ score...<div class='webex-radiogroup' id='radio_FIOCOAKKNV'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FIOCOAKKNV\" value=\"\"></input> <span>the less autistic-like traits displayed</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FIOCOAKKNV\" value=\"\"></input> <span>has no relation to autistic-like traits</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FIOCOAKKNV\" value=\"answer\"></input> <span>the more autistic-like traits displayed</span></label></div>\n  \n\n* Assuming that your code all worked, what was the AQ score (just the number) of Participant ID No. 87: <div class='webex-radiogroup' id='radio_TGEGSNBJIS'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_TGEGSNBJIS\" value=\"answer\"></input> <span>2</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_TGEGSNBJIS\" value=\"\"></input> <span>3</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_TGEGSNBJIS\" value=\"\"></input> <span>5</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_TGEGSNBJIS\" value=\"\"></input> <span>6</span></label></div>\n  \n\n* Type in the box how many participants had an AQ score of 3 (again just the number): <input class='webex-solveme nospaces' size='10' data-answer='[\"13\"]'/>  \n\n* The cut-off for the AQ10 is usually said to be around 6 meaning that anyone with a score of more than 6 should be referred for diagnostic assessment. Based on this data, how many participants might be referred for further assessment? <div class='webex-radiogroup' id='radio_PDHEPOJPQE'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PDHEPOJPQE\" value=\"\"></input> <span>2</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PDHEPOJPQE\" value=\"\"></input> <span>4</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PDHEPOJPQE\" value=\"answer\"></input> <span>6</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PDHEPOJPQE\" value=\"\"></input> <span>8</span></label></div>\n\n\n\n\n<div class='webex-solution'><button>Explain these answers</button>\n\n\n::: {.cell layout-align=\"center\"}\n\n1. As mentioned, the higher the score on the AQ10 the more autistic-like traits a participant is said to show.\n\n2. You could do this by code with `filter(aq_scores, Id == 87)`, which would give you a tibble of 1x2 showing the ID number and score. If you just wanted the score you could use `pull()` but we haven't shown you that yet: `filter(aq_scores, Id == 87) %>% pull(AQ)`. The answer is an AQ score of 2.\n\n3. Same as above but changing the argument of the filter. `filter(aq_scores, AQ == 3) %>% count()`. The answer is 13. Remember you can do this by counting but the code makes it reproducible and accurate every time. You might make mistakes.\n\n4. `filter(aq_scores, AQ > 6) %>% count()` or `filter(aq_scores, AQ >= 7) %>% count()`. The answer is 6.\n        \n:::\n\n\n</div>\n  \n\n**Recap on Wickham Verbs!**\n\nWhich function(s) would you use to approach each of the following problems?\n\n* We have a dataset of 400 adults, but we want to remove anyone with an age of 50 years or more. To do this, we could use the <select class='webex-select'><option value='blank'></option><option value=''>mutate()</option><option value=''>arrange()</option><option value=''>group_by()</option><option value=''>summarise()</option><option value='answer'>filter()</option><option value=''>select()</option></select> function.\n\n* We are interested in overall summary statistics for our data, such as the overall average and total number of observations. To do this, we could use the <select class='webex-select'><option value='blank'></option><option value=''>group_by()</option><option value=''>arrange()</option><option value=''>mutate()</option><option value=''>select()</option><option value=''>filter()</option><option value='answer'>summarise()</option></select> function.\n\n* Our dataset has a column with the number of cats a person has, and a column with the number of dogs. We want to calculate a new column which contains the total number of pets each participant has. To do this, we could use the <select class='webex-select'><option value='blank'></option><option value=''>select()</option><option value=''>summarise()</option><option value=''>group_by()</option><option value=''>filter()</option><option value='answer'>mutate()</option><option value=''>arrange()</option></select> function.\n\n* We want to calculate the average for each participant in our dataset. To do this we could use the <select class='webex-select'><option value='blank'></option><option value=''>arrange() and mutate()</option><option value=''>filter() and select()</option><option value='answer'>group_by() and summarise()</option><option value=''>group_by() and arrange()</option></select> functions.\n\n* We want to order a dataframe of participants by the number of cats that they own, but want our new dataframe to only contain some of our columns. To do this we could use the <select class='webex-select'><option value='blank'></option><option value='answer'>arrange() and select()</option><option value=''>group_by() and mutate()</option><option value=''>select() and summarise()</option><option value='answer'>filter() and select()</option></select> functions.\n\n\n\n<div class='webex-solution'><button>Explain these Answers</button>\n\n\n::: {.cell layout-align=\"center\"}\n\n* `filter()` helps us keep and remove rows!\n* `summarise()` is the main function for creating means, medians, modes, etc.\n* `mutate()` can be used to add columns to help add more information.\n* When you want summary statistics for individual groups or participants you have to first `group_by()` and then `summarise()`.\n* You would need to `filter()` first to reduce the people based on their number of cats and then just `select()` the columns you want to keep.\n:::\n\n\n</div>\n\n\n### Error mode\n\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using the functions `filter()`, `count()`, and `group_by()` and `summarise()`. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently. \n\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load `tidyverse` and the data file: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\npong_data <- read_csv(\"data/witt_2018.csv\")\n```\n:::\n\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load `tidyverse` and the data. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\n\n- SD not sd function \n\n- mean on scale scores\n\n- adding object in each pipe step \n\n## Words from this Chapter\n\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the [PsyTeachR Glossary](https://psyteachr.github.io/glossary/){target=\"_blank\"}. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n::: {.cell layout-align=\"center\"}\n\n|term                                              |definition                                                                                              |\n|:-------------------------------------------------|:-------------------------------------------------------------------------------------------------------|\n|[data-wrangling](https://psyteachr.github.io/glossary/d#data-wrangling){target='_blank' class='glossary'}|The process of preparing data for visualisation and statistical analysis.                               |\n|[function](https://psyteachr.github.io/glossary/f#function){target='_blank' class='glossary'}|A named section of code that can be reused.                                                             |\n|[long](https://psyteachr.github.io/glossary/l#long){target='_blank' class='glossary'}|A data format where each observation is on a separate row                                               |\n|[package](https://psyteachr.github.io/glossary/p#package){target='_blank' class='glossary'}|A group of R functions.                                                                                 |\n|[pipe](https://psyteachr.github.io/glossary/p#pipe){target='_blank' class='glossary'}|A way to order your code in a more readable format using the symbol %>%                                 |\n|[pivot_longer()](https://psyteachr.github.io/glossary/p#pivot_longer()){target='_blank' class='glossary'}|Gather data by increasing the number of rows and decreasing the number of columns.                      |\n|[reverse-code](https://psyteachr.github.io/glossary/r#reverse-code){target='_blank' class='glossary'}|Having two similar questions, one expressed in a positive way, and another expressed in a negative way. |\n|[tibble](https://psyteachr.github.io/glossary/t#tibble){target='_blank' class='glossary'}|A container for tabular data with some different properties to a data frame                             |\n|[tidy-data](https://psyteachr.github.io/glossary/t#tidy-data){target='_blank' class='glossary'}|A format for data that maps the meaning onto the structure.                                             |\n|[wide](https://psyteachr.github.io/glossary/w#wide){target='_blank' class='glossary'}|A data format where all of the observations about one subject are in the same row                       |\n:::\n\n\n## End of chapter\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!\n\nBrilliant work again today! You have now recapped one-table verbs and started to expand your knowledge of two-table verbs. These are great to know as for example, as seen above, it actually only took a handful of reproducible steps to get from messy data to tidy data; could you imagine doing this by hand in Excel through cutting and pasting? Not to mention the mistakes you could make! Excellent work! You are a DataWrangling expert! Before finishing, remember to go over anything you are unsure of, and if you have any questions, please post them on Teams. There are some additional questions below to help you check your understanding.\n",
    "supporting": [
      "06-wrangling-3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}