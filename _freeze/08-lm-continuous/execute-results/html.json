{
  "hash": "807c6658acd1e25aec6defbc1e8c9c23",
  "result": {
    "markdown": "# Regression with one continuous predictor\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nSo far in this book we have been building your skills and knowledge on data wrangling and you now have the basis for a lot of the work you will do in research. You may think that the tasks we ask you to do will get harder as this course progresses but that isn't true. The hardest part of working with data is at the very beginning, trying to learn the new terminology, figuring out how to load in data and wrangle it into the format you need. And whilst it may feel like you have not yet covered a lot, it is really worth reflecting on just how far you've come in a short time..\n\nWe will talk a little bit about these two correlations in the work we do today. And we shall begin now!\n\n**Chapter Intended Learning Outcomes (ILOs)**\n\nBy the end of this chapter, you will be able to: \n\n- ILO1.\n\n## Chapter preparation\n\n### Introduction to the data set \n\nFor this chapter, we are using open data from @dawtry_why_2015. The abstract of their article is:\n\n> The present studies provide evidence that social-sampling processes lead wealthier people to oppose redistribution policies. In samples of American Internet users, wealthier participants reported higher levels of wealth in their social circles (Studies 1a and 1b). This was associated, in turn, with estimates of higher mean wealth in the wider U.S. population, greater perceived fairness of the economic status quo, and opposition to redistribution policies. Furthermore, results from a large-scale, nationally representative New Zealand survey revealed that low levels of neighborhood-level socioeconomic deprivation?an objective index of wealth within participants' social circles mediated the relation between income and satisfaction with the economic status quo (Study 2). These findings held controlling for relevant variables, including political orientation and perceived self-interest. Social-structural inequalities appear to combine with social-sampling processes to shape the different political attitudes of wealthier and poorer people.\n\nIn summary, the authors investigated why people with more money tend to oppose wealth redistribution policies to decrease inequality in society. We are using data from Study 1A where 305 people completed measures on household income, predicted population income, their predicted social circle income, in addition to measures on support for wealth redistribution and fairness and satisfaction with the current system. \n\nThey predicted people with higher incomes have social circles with higher incomes, so they are more satisfied with the current system of wealth redistribution and less interested in changing it. In essence, poorer people and richer people have different experiences of how rich and equal their country is. In this chapter, we will explore the relationship between a range of these variables. \n\n### Organising your files and project for the chapter\n\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\n1. In your folder for research methods and the book `ResearchMethods1_2/Quant_Fundamentals`, create a new folder called `Chapter_08_regression_continuous`. Within `Chapter_07_dataviz`, create two new folders called `data` and `figures`.\n\n2. Create an R Project for `Chapter_08_regression_continuous` as an existing directory for your chapter folder. This should now be your working directory.\n\n3. Create a new R Markdown document and give it a sensible title describing the chapter, such as `08 Correlations and Regression`. Delete everything below line 10 so you have a blank file to work with and save the file in your `Chapter_08_regression_continuous` folder. \n\n4. We are working with a new data set, so please save the following data file: [Dawtry_2015.csv](data/Dawtry_2015.csv). Right click the link and select \"save link as\", or clicking the link will save the files to your Downloads. Make sure that you save the file as \".csv\". Save or copy the file to your `data/` folder within `Chapter_08_regression_continuous`.\n\nYou are now ready to start working on the chapter! \n\n### Activity 1 - Read and wrangle the data\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. Create an object called `dawtry_data` to be consistent with the tasks below. If you want to focus on correlations and regression, then you can just type the code in the solution. \n\n::: {.callout-tip}\n#### Try this\n\nTo wrangle the data, complete the following tasks: \n\n1. Load the <pkg>tidyverse</pkg> package. \n\n2. Read the data file `data/Dawtry_2015.csv` to the object name `dawtry_data`.\n\n3. Reverse code two items: `redist2` and `redist4` to create two new variables `redist2_R` and `redist4_R`\n\n4. Summarise the data to calculate the mean `fairness_satisfaction` score, by taking the mean of two items: `fairness` and `satisfaction`. \n\n5. Summarise the data to calculate the mean `redistribution` score, by taking the mean of four items: `redist1`, `redist2_R`, `redist3`, and `redist4_R`.\n\n6. Create a new object called `dawtry_clean` by joining `dawtry_data` with your two new variables `fairness_satisfaction` and `redistribution`. \n\n7. Decrease the number of columns in `dawtry_clean` by selecting `PS`, all the columns between `Household_Income` and `redistribution`, but removing the two reverse coded items `redist2_R` and `redist4_R`. \n\nYour data should look like this to be ready to analyse:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nRows: 305\nColumns: 11\n$ PS                                  <dbl> 233, 157, 275, 111, 52, 11, 76, 90…\n$ Household_Income                    <dbl> NA, 20.00, 100.00, 150.00, 500.00,…\n$ Political_Preference                <dbl> 5, 5, 5, 8, 5, 3, 4, 3, 2, 3, NA, …\n$ age                                 <dbl> 40, 59, 41, 59, 35, 34, 36, 39, 40…\n$ gender                              <dbl> 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, NA, …\n$ Population_Inequality_Gini_Index    <dbl> 38.78294, 37.21451, 20.75000, 35.3…\n$ Population_Mean_Income              <dbl> 29715, 123630, 60000, 59355, 15360…\n$ Social_Circle_Inequality_Gini_Index <dbl> 28.056738, 24.323388, 14.442577, 2…\n$ Social_Circle_Mean_Income           <dbl> 21150, 65355, 107100, 86640, 56850…\n$ fairness_satisfaction               <dbl> 1.0, 3.5, 5.0, 7.0, 4.5, 2.5, 3.0,…\n$ redistribution                      <dbl> 5.50, 3.25, 3.75, 2.75, 3.00, 3.75…\n```\n:::\n:::\n\n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\n# This should be the Dawtry_2015.csv file \ndawtry_data <- read_csv(\"data/Dawtry_2015.csv\")\n\n# Reverse code redist2 and redist4\ndawtry_data <- dawtry_data %>%\n  mutate(redist2_R = 7 - redist2,\n         redist4_R = 7 - redist4)\n\n# calculate mean fairness and satisfaction score  \nfairness_satisfaction <- dawtry_data %>% \n  pivot_longer(cols = fairness:satisfaction, \n               names_to = \"Items\", \n               values_to = \"Response\") %>% \n  group_by(PS) %>% \n  summarise(fairness_satisfaction = mean(Response)) %>% \n  ungroup()\n\n# calculate mean wealth redistribution score  \nredistribution <- dawtry_data %>% \n  pivot_longer(cols = c(redist1, redist2_R, redist3, redist4_R), \n               names_to = \"Items\", \n               values_to = \"Response\") %>% \n  group_by(PS) %>% \n  summarise(redistribution = mean(Response)) %>% \n  ungroup()\n\n# join data and select columns for focus\ndawtry_clean <- dawtry_data %>% \n  inner_join(fairness_satisfaction, by = \"PS\") %>% \n  inner_join(redistribution, by = \"PS\") %>% \n  select(PS, Household_Income:redistribution, -redist2_R, -redist4_R)\n```\n:::\n\n\n:::\n\n### Activity 2 - Explore the data\n\n::: {.callout-tip}\n#### Try this\nAfter the wrangling steps, try and explore `dawtry_clean` to see what variables you are working with. For example, opening the data object as a tab to scroll around, explore with `glimpse()`, or try plotting some of the individual variables using a histogram. \n:::\n\nIn `dawtry_clean`, we have the following variables:\n\n| Variable       |       Type                       |           Description          |\n|:--------------:|:---------------------------------|:-------------------------------|\n| PS | double| Participant ID number. |\n| Household_Income | double| Household income in US Dollars (\\$). |\n| Political_Preference | double| Political attitudes: 1 = very liberal/very left-wing/strong Democrat to 7 = very conservative/very right-wing/strong Republican. |\n| age | double| Age in years. |\n| gender | double| 1 = \"Male\", 2 = \"Female. |\n| Population_Inequality_Gini_Index | double| Measure of income inequality from 0 (perfect equality) to 1 (perfect inequality), here where participants estimated population in equality. |\n| Population_Mean_Income | double| Participant estimate of the mean household income in the population (\\$). |\n| Social_Circle_Inequality_Gini_Index | double| Measure of income inequality from 0 (perfect equality) to 1 (perfect inequality), here where participants estimated inequality in their social circle. |\n| Social_Circle_Mean_Income | double| Participant estimate of the mean household income in their social circle (\\$). |\n| fairness_satisfaction | double| Perceived fairness and satisfaction about the current system of wealth redistribution: Mean of two items (1 extremely fair – 9 extremely unfair) |\n| redistribution | double| Attitudes on wealth distribution: Mean of four items (1 strongly disagree – 6 strongly agree). |\n\nWe will use this data set to demonstrate correlations and regression when you have one continuous predictor. \n\n## Correlation\n\nBefore we cover regression as a more flexible framework for inferential statistics, we think it is useful to start with correlation to get a feel for how we can capture the relationship between two variables. As a reminder from the materials, correlations are standardised to range from -1 (a perfect negative correlation) to 1 (a perfect positive correlation). A value of 0 would mean there is no correlation between your variables. \n\n### Activity 3 - Visualise the relationship\n\nTo explore the relationship between two variables, it is useful to create a scatterplot early for yourself, then provide a more professional looking version to help communicate your results. \n\n::: {.callout-tip}\n#### Try this\n\nUsing your data visualisation skills from Chapter 7, recreate the scatterplot below using the variables `fairness_satisfaction` and `redistribution` from `dawtry_clean`. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-lm-continuous_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nLooking at the graph, we can describe the relationship as <select class='webex-select'><option value='blank'></option><option value=''>positive</option><option value=''>little to no correlation</option><option value='answer'>negative</option></select>.\n:::\n\n::: {.callout-caution collapse=\"true\"}\n#### Show me the solution\nThe scatterplot shows a negative correlation between the two variables. As attitudes on wealth redistribution increase to be more positive, perceived fairness and satisfaction tends to decrease. This makes sense as people who are more dissatisfied with the current system think there should be more wealth redistribution stategies. \n\nYou should have the following in a code chunk: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndawtry_clean %>% \n  ggplot(aes(x = fairness_satisfaction, y = redistribution)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  scale_x_continuous(name = \"Perceived Fairness and Satisfaction\", \n                     breaks = c(1:9)) + \n  scale_y_continuous(name = \"Attitudes on Wealth Distribution\", \n                     breaks = c(1:6))\n```\n\n::: {.cell-output-display}\n![](08-lm-continuous_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n### Activity 4 - Calculate the correlation coefficient\n\nVisualising the relationship between two variables is great for our understanding, but it does not tell us anything about the inferential statistics for what we can learn from our sample in hypothesis testing and measures of effect size.\n\nA correlation is a specific application of the general linear model. We want to capture the covariation between two variables. If you are interested, see the Handy Workbook ([McAleer, 2023](https://psyteachr.github.io/handyworkbook/pearson-correlation.html){target=\"_blank\"}) for the calculations behind correlation and how it represents the covariance of two variables compared to their total variability. They are not the only methods, but the two most common versions of a correlation are:\n\n-  Pearson's product-moment correlation (often shortened to the <a class='glossary' title='A standardised measure of the linear relationship between two variables that makes stringent assumptions about the population.'>Pearson</a> correlation) and symbolised by **r**\n\n- Spearman's rank correlation coefficient (often shortened to the <a class='glossary' title='A standardised measure of the relationship between two variables that assumes a monotonic - but not necessarily a linear - relationship and makes less stringent assumptions about the population.'>Spearman</a> correlation) and symbolised by $r_s$ or sometimes the Greek letter **rho** $\\rho$\n\nThere is a function built into R (`cor.test()`) to calculate the correlation between two variables, but we tend to use the `correlation()` function from the <pkg>correlation</pkg> package as it has more complete reporting features. The `correlation()` function requires:\n\n- The name of the data set you are using\n\n- The name of the first variable you want to select for the correlation\n\n- The name of the second variable you want to select for the correlation\n\n- The type of correlation you want to run: e.g. `pearson`, `spearman`\n\nFor our `dawtry_clean` data, we would run the following code for a two-tailed Pearson correlation:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncorrelation(data = dawtry_clean, \n            select = \"fairness_satisfaction\", \n            select2 = \"redistribution\",  \n            method = \"pearson\", \n            alternative = \"two.sided\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter1            |Parameter2     |        r|   CI|     CI_low|    CI_high|         t| df_error|p      |Method              | n_Obs|\n|:---------------------|:--------------|--------:|----:|----------:|----------:|---------:|--------:|:------|:-------------------|-----:|\n|fairness_satisfaction |redistribution | -0.70034| 0.95| -0.7533907| -0.6382316| -17.07843|      303|< .001 |Pearson correlation |   305|\n\n</div>\n:::\n:::\n\n\nYour output will look a little different due to how our book renders tables, but you should get the same information. For the three key concepts of inferential statistics, we get \n\n- **Hypothesis testing**: *p* < .001, suggesting we can reject the null hypothesis assuming $\\alpha$ = .05. \n\n- **Effect size**: *r* = -.70, suggesting a strong negative correlation. \n\n- **Confidence interval**: [-0.75, -0.64], showing the precision around the effect size estimate.   \n\nTo summarise, there was a strong, negative, statistically significant relationship between attitudes on wealth redistribution and perceived fairness and satisfaction, *r* (303) = -0.70, *p* < .001, 95% CI = [-0.75, -0.64].\n\nIf we had reason to use a Spearman correlation instead, all we need to do is change the `method` argument. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncorrelation(data = dawtry_clean, \n            select = \"fairness_satisfaction\", \n            select2 = \"redistribution\",  \n            method = \"spearman\", \n            alternative = \"two.sided\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter1            |Parameter2     |        rho|   CI|    CI_low|    CI_high|       S|p      |Method               | n_Obs|\n|:---------------------|:--------------|----------:|----:|---------:|----------:|-------:|:------|:--------------------|-----:|\n|fairness_satisfaction |redistribution | -0.6806667| 0.95| -0.738182| -0.6133274| 7947402|< .001 |Spearman correlation |   305|\n\n</div>\n:::\n:::\n\n\n::: {.callout-tip}\n#### Try this\n\nGreat work following along so far, but now it is time to test your understanding on a new set of variables. This time, use the variables `age` and `redistribution` from `dawtry_clean`. We can ask the question \"What is the relationship between age and attitudes on wealth redistribution?\". \n\n1. Create a scatterplot to visualise the relationship between `age` and `redistribution` from `dawtry_clean`. \n\n2. Apply the Pearson correlation to get your inferential statistics and answer the following questions: \n\n    - **Hypothesis testing**: Assuming $\\alpha$ = .05, the relationship between age and wealth redistribution is <select class='webex-select'><option value='blank'></option><option value=''>statistically significant</option><option value='answer'>not statistically significant</option></select>.\n    \n    - **Effect size**: Rounded to 2 decimals, the value for Pearson's correlation coefficient is <select class='webex-select'><option value='blank'></option><option value=''>-0.14</option><option value='answer'>-0.03</option><option value=''>0.08</option><option value=''>-0.49</option></select>.\n    \n    - **Confidence interval**: Rounded to 2 decimals, the lower bound is <select class='webex-select'><option value='blank'></option><option value='answer'>-0.14</option><option value=''>-0.03</option><option value=''>0.08</option><option value=''>-0.49</option></select> and the upper bound is <select class='webex-select'><option value='blank'></option><option value=''>-0.14</option><option value=''>-0.03</option><option value='answer'>0.08</option><option value=''>-0.49</option></select>.\n:::\n\n::: {.callout-caution collapse=\"true\"}\n#### Show me the solution\nThe scatterplot shows very little correlation between the two variables. The regression line is almost flat and there does not appear to be a clear pattern to the data points. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndawtry_clean %>% \n  ggplot(aes(x = age, y = redistribution)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  scale_y_continuous(name = \"Attitudes on Wealth Distribution\", \n                     breaks = c(1:6))\n```\n\n::: {.cell-output-display}\n![](08-lm-continuous_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nFor our inferential statistics, the relationship is not statistically significant and the Pearson correlation coefficient is very weak, *r* (302) = -0.03, *p* = .625, 95% CI = [-0.14, 0.08]. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncorrelation(data = dawtry_clean, \n            select = \"age\", \n            select2 = \"redistribution\",  \n            method = \"pearson\", \n            alternative = \"two.sided\")\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter1 |Parameter2     |          r|   CI|     CI_low|   CI_high|          t| df_error|         p|Method              | n_Obs|\n|:----------|:--------------|----------:|----:|----------:|---------:|----------:|--------:|---------:|:-------------------|-----:|\n|age        |redistribution | -0.0281749| 0.95| -0.1402227| 0.0845855| -0.4898215|      302| 0.6246159|Pearson correlation |   304|\n\n</div>\n:::\n:::\n\n\n:::\n\n## Linear regression with one continuous predictor\n\nNow you know how to calculate a correlation in R, we can turn to simple linear regression as a more flexible tool for modelling the relationship between variables. \n\nIn Research Methods 1, we focus on just two variables, before scaling up to more complicated models in Research Methods 2. In this chapter, we focus the relationship between a continuous <a class='glossary' title=''>outcome</a> and one continuous <a class='glossary' title=''>predictor</a>, before extending the framework to one categorical predictor in Chapter 9. There is also a chapter in the Handy Workbook ([McAleer, 2023](https://psyteachr.github.io/handyworkbook/simple-linear-regression.html){target=\"_blank\"}) dedicated to manually calculating simple linear regression.\n\n### Activity 5- Calculating descriptive statistics\n\nFor all the information we want to include in a report, calculating descriptive statistics is helpful for the reader to show the context behind the results you present. Here, we can report the mean and standard deviation of our two variables.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndawtry_clean %>% \n  # pivot longer to avoid repeating yourself\n  pivot_longer(cols = fairness_satisfaction:redistribution,\n               names_to = \"Variable\", \n               values_to = \"Value\") %>% \n  # group by Variable to get one value per variable\n  group_by(Variable) %>% \n  # mean and SD, rounded to 2 decimals\n  summarise(mean_variable = round(mean(Value), 2),\n            sd_variable = round(sd(Value), 2))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Variable              | mean_variable| sd_variable|\n|:---------------------|-------------:|-----------:|\n|fairness_satisfaction |          3.54|        2.02|\n|redistribution        |          3.91|        1.15|\n\n</div>\n:::\n:::\n\n\n::: {.callout-note}\nIf you want some reinforcement of how these skills apply to published research, look at Table 1 in @dawtry_why_2015. The means and standard deviations here (and the correlation in Activity 4) exactly reproduce the values they report.\n:::\n\nIf other types of descriptive statistic would be more suitable to your data, then you can just replace the functions you use within `summarise()`. \n\n### Activity 6 - Using the `lm()` function \n\nFor our research question of \"is there a relationship between support for wealth redistribution and fairness and satisfaction\", we can address it with simple linear regression. \n\nInstead of a standardised correlation coefficient, we can frame it as whether knowing fairness and satisfaction can predict values of support for wealth redistribution. The design is still correlational, so it does not tell us anything about a causal relationship in isolation. We use the word predict in the statistical sense, where we can ask whether knowing values of one variable help us predict values of another variable. \n\nThe first step is to create an object (`lm_redistribution`) for the linear model.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_redistribution <- lm(redistribution ~ fairness_satisfaction,\n                        data = dawtry_clean)\n```\n:::\n\n\nThe function `lm()` is built into R and is incredibly flexible for creating linear regression models. \n\n- The first argument is to specify a formula which defines our model. The first component (`redistribution`) is our outcome variable for what we are interested in modelling. \n\n- The tilde (`~`) separates the equation, where everything on the right is your predictor variable(s). In simple linear regression, we just have one predictor, which is `fairness_satisfaction` in our model here. This is saying we want to predict `redistribution` as our outcome from `fairness_satisfaction` as our predictor. \n\n- We then specify the data frame we want to use.\n\nWhen you create this object, it stores a bunch of information, but does not really tell us all the statistics we expect. If you simply print the object in the console, it will tell you the intercept and coefficient(s), but none of the model fitting nor hypothesis testing values. If you look at the object in the R environment, you will see it is a <a href='https://psyteachr.github.io/glossary/l#list' target='_blank' class='glossary' title='A container data type that allows items with different data types to be grouped together.'>list</a> containing several elements. It stores things like the model, the residuals, and other information you can use.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_redistribution\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = redistribution ~ fairness_satisfaction, data = dawtry_clean)\n\nCoefficients:\n          (Intercept)  fairness_satisfaction  \n               5.3169                -0.3975  \n```\n:::\n:::\n\n\nTo get that extra information, we need to call the `summary()` function around the linear model object to explore it's properties like estimates and model fit.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(lm_redistribution)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = redistribution ~ fairness_satisfaction, data = dawtry_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9193 -0.5279  0.0233  0.4782  3.3634 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            5.31686    0.09488   56.04   <2e-16 ***\nfairness_satisfaction -0.39754    0.02328  -17.08   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8218 on 303 degrees of freedom\nMultiple R-squared:  0.4905,\tAdjusted R-squared:  0.4888 \nF-statistic: 291.7 on 1 and 303 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nTo walk through the output, `Call:` summarises the model you specified. `Residuals:` provides a summary of the model residuals which we will come back to later. `Coefficients:` provides our model output, this time with inferential statistics. The two key lines are:\n\n1. `(Intercept)` - This is the value of the outcome when our predictor is set to 0. For a fairness and satisfaction value of 0, we would expect a value of 5.32 for redistribution. You get a *p*-value for this, but in isolation it is not too useful. It just compares the intercept estimate to 0 which typically you are not interested in.\n\n- `fairness_satisfaction` - This is the regression slope or coefficient. This is the change in the outcome for every 1 unit change in the predictor. So, for every 1 unit increase in fairness and satisfaction, we expect support for wealth redistribution to decrease (as we have a negative value) by 0.40 units. This is consistent with the correlation as we have a negative relationship between the two variables. Looking at the *p*-value, this is statistically significant (*p* < .001), suggesting we can reject the null hypothesis and conclude there is an effect here.\n\n::: {.callout-note}\n#### Does it matter if the slope is positive or negative? \nWhen you have a continuous predictor, the sign is important to keep in mind. A positive slope would mean an increase in the predictor is associated with increased values of your outcome. A negative slope would mean an increase in the predictor is associated with decreased values of your outcome. This is crucial for interpreting the coefficient. \n:::\n\nAt the bottom of the model output, you then get the fit statistics. Multiple \n$R^2$ tells you how much variance in your outcome your predictor(s) explain. Adjusted $R^2$ tends to be more conservative as it adjusts for the number of predictors in the model (something we will not cover until Chapter 14), but they will be very similar when you have one predictor. Adjusted $R^2$ is .49, suggesting fairness and satisfaction explains 49% of the variance in support for wealth redistribution.\n\nFinally, we have the model fit statistics to tell us whether the model explains a significant amount of variance in the outcome. With one predictor, the *p*-value next to the coefficient and next to the model fit will be identical, as one predictor is the whole model. The F-statistic is 291.7, the model degrees of freedom is 1, the residual degrees of freedom is 303, and the *p*-value is *p* < .001.\n\n::: {.callout-important}\n#### What does 2e-16 mean? \nFor the *p*-value here, the output looks a little weird. R reports very small or very large numbers using scientific notation to save space. We normally report *p*-values to three decimals, so we report anything smaller as *p* < .001 to say it is smaller than this.\n\nIf you want to see the real number, you can use the following function which shows just how small the *p*-value is:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nformat(2e-16, scientific = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0.0000000000000002\"\n```\n:::\n:::\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### How are correlation and regression the same? \n\nIf you are interested in the relationship between the two concepts, we said correlation was a specific application of the general linear model. It describes the - standardised - covariation between two variables compared to their total variability. For values of -1 and 1, knowing the value of one variable perfectly correlates to the value of your other variable. As you approach 0, the relationship between the variables is less perfect, meaning there is more variability left over compared to the covariance.\n\nIn regression, we frame it as how much variance you explain compared to the total amount of variance. The more variance your predictor explains, the less unexplained variance there is left over. We no longer calculate *r*, we calculate $R^2$ as the proportion of variance in your outcome explained by your model. A value of 0 would be you explain no variance and a value of 1 means you explain all the variance.  \n\nYou can see the connection between the two by comparing the value of Pearson's *r* from Activity 4 (-.70) to the value of $R^2$ = .4905. If you take the square root to get *r* (`sqrt(.4905)`), you get .70, which is exactly the same absolute value since $R^2$ can only be positive. \n\nSo, when you have a single continuous predictor, it is the exact same process as correlation, just expressed slightly different. \n:::\n\n::: {.callout-tip}\n#### Try this\n\nGreat work following along so far, but now it is time to test your understanding on a new set of variables. This time, use `redistribution` as your outcome, `age` as your predictor, and use `dawtry_clean` as your data. We can ask the same question as before: \"What is the relationship between age and attitudes on wealth redistribution?\". \n\n1. Apply simple linear regression to get your inferential statistics and answer the following questions: \n\n    - **Hypothesis testing**: Assuming $\\alpha$ = .05, the relationship between age and wealth redistribution is <select class='webex-select'><option value='blank'></option><option value=''>statistically significant</option><option value='answer'>not statistically significant</option></select>.\n    \n    - **Effect size**: Rounded to 2 decimals, the value for Pearson's correlation coefficient is <select class='webex-select'><option value='blank'></option><option value=''>-0.14</option><option value='answer'>-0.03</option><option value=''>0.08</option><option value=''>-0.49</option></select>.\n    \n    - **Confidence interval**: Rounded to 2 decimals, the lower bound is <select class='webex-select'><option value='blank'></option><option value='answer'>-0.14</option><option value=''>-0.03</option><option value=''>0.08</option><option value=''>-0.49</option></select> and the upper bound is <select class='webex-select'><option value='blank'></option><option value=''>-0.14</option><option value=''>-0.03</option><option value='answer'>0.08</option><option value=''>-0.49</option></select>.\n:::\n\n::: {.callout-caution collapse=\"true\"}\n#### Show me the solution\nBlah\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n:::\n\n### Hypothesis testing, effect sizes, and confidence intervals\n\n### Centering predictors\n\n### Visualising model estimates\n\n## Checking assumptions\n\n## Reporting your results\n\n## Test Yourself\n\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter. \n\n### Knowledge check\n\nLook at this code and answer the following questions:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresults <- correlation(data = mh, \n                       select = \"IQ\", \n                       select2 = \"Home\",  \n                       method = \"pearson\", \n                       alternative = \"two.sided\")\n```\n:::\n\n\n1. What would this analysis show? <div class='webex-radiogroup' id='radio_DXCEBSENSN'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DXCEBSENSN\" value=\"answer\"></input> <span>the relationship between IQ and the time spent reading at home</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DXCEBSENSN\" value=\"\"></input> <span>the relationship between IQ and the time spent watching TV at home</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DXCEBSENSN\" value=\"\"></input> <span>the relationship between IQ and Reading Ability</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_DXCEBSENSN\" value=\"\"></input> <span>the effect of IQ on time spent reading at Home</span></label></div>\n\n2. What type of correlation analysis is it? <div class='webex-radiogroup' id='radio_VNIPLWIWBF'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VNIPLWIWBF\" value=\"\"></input> <span>one-tailed spearman analysis</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VNIPLWIWBF\" value=\"answer\"></input> <span>two-tailed pearson analysis</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VNIPLWIWBF\" value=\"\"></input> <span>one-tailed pearson analysis</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VNIPLWIWBF\" value=\"\"></input> <span>two-tailed spearman analysis</span></label></div>\n\n\nNow try running the code and then answering the following questions.\n\n3. To three decimal places, what is the r-value of the correlation between IQ and the time spent reading at Home? ` longmcq(sample(c(answer = rv, tv, civ, pv)))`\n\n4. To three decimal places, what is the p-value of the correlation between IQ and the time spent reading at Home? ` longmcq(sample(c(answer = pv, tv, civ, rv)))`\n\n5. What is the degrees of freedom of the correlation between IQ and the time spent reading at Home? ` longmcq(sample(c(answer = dfv, tv, civ, nv)))`\n\n\n<div class='webex-solution'><button>Explain these answers</button>\n\n\n::: {.cell layout-align=\"center\"}\n\nThis analysis is a two-tailed pearson correlation looking at the relationship between IQ and the amount of time spent reading at home. You can tell this from the two variables in the code being IQ and Home, and the code stating pearson, and two-sided (another name for two-tailed). If you run the analysis you will find that the result would be r(23) = .202, p = .334.\n:::\n\n\n</div>\n\n\n### Error mode\n\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on the new types of data visualisation. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently. \n\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load <pkg>tidyverse</pkg> and wrangle the data files: \n\n## Words from this Chapter\n\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the [PsyTeachR Glossary](https://psyteachr.github.io/glossary/){target=\"_blank\"}. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term                                        |definition                                                                                                                                                                                         |\n|:-------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|[list](https://psyteachr.github.io/glossary/l#list){target='_blank' class='glossary'}|A container data type that allows items with different data types to be grouped together.                                                                                                          |\n|[outcome](https://psyteachr.github.io/glossary/o#outcome){target='_blank' class='glossary'}|                                                                                                                                                                                                   |\n|[pearson](https://psyteachr.github.io/glossary/p#pearson){target='_blank' class='glossary'}|A standardised measure of the linear relationship between two variables that makes stringent assumptions about the population.                                                                     |\n|[predictor](https://psyteachr.github.io/glossary/p#predictor){target='_blank' class='glossary'}|                                                                                                                                                                                                   |\n|[spearman](https://psyteachr.github.io/glossary/s#spearman){target='_blank' class='glossary'}|A standardised measure of the relationship between two variables that assumes a monotonic - but not necessarily a linear - relationship and makes less stringent assumptions about the population. |\n:::\n:::\n\n\n## End of chapter\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!\n\nExcellent work today! You can now add running, interpreting and writing up correlations to the list of knowledge and skills in your research methods toolbox. Remember that actually a lot of the work is in the preparation of the data and really running the correlation is just one more function. It might be worthwhile repeating the first few activities with two other variables to test your understanding. If you have any questions, please post them on Teams.\n",
    "supporting": [
      "08-lm-continuous_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}