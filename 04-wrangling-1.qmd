# Data wrangling 1: Join, select, and mutate {#04-wrangling-1}

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(babynames)

# Load the tidyverse package 
library(tidyverse)

# Load the two data files
dat <- read_csv("data/ahi-cesd.csv")
pinfo <- read_csv("data/participant-info.csv")
```

In this chapter, we start our exploration of `r glossary("data wrangling")`. Some of you might have experience painstakingly copying and pasting values into new columns or trying to match up values from multiple spreadsheets. As well as taking a long time, there is so much room for error as you might repeat or miss values. 

We have mentioned a few times now the benefits of working with R/RStudio to develop reproducible research practices over the first few chapters.But, if you take nothing else away from these materials, developing your data wrangling skills is one of the primary benefits that will benefit you in many assessments and careers.

Researchers actually spend far more of their time cleaning and preparing their data than they spend analysing it. @dasu2003 estimated that up to 80% of time spent on data analysis involves data preparation tasks! Although every data set presents unique challenges, there are some systematic principles that you will constantly use to make your analyses less error-prone and more efficient. Our mantra is: the data changes but the skills stay the same. 

Over the next three chapters, we are going to introduce you to a range of functions within the `tidyverse` for wrangling data. In this chapter, we will cover joining two data sets by a common identifier, selecting columns to simplify your data, arranging values within a data set, and mutating data to create new variables.   

**Chapter Intended Learning Outcomes (ILOs)**

By the end of this chapter, you will be able to: 

- ILO1

## Chapter preparation

### Introduction to the data set 

For this chapter, we are using open data from @woodworth_data_2018 one more time. In the last two chapters, we asked you to trust us and copy some code until we reached data wrangling, and now is the time to fill in those gaps. If you need a reminder, the abstract of their article is: 

> We present two datasets. The first dataset comprises 992 point-in-time records of self-reported happiness and depression in 295 participants, each assigned to one of four intervention groups, in a study of the effect of web-based positive-psychology interventions. Each point-in-time measurement consists of a participant’s responses to the 24 items of the Authentic Happiness Inventory and to the 20 items of the Center for Epidemiological Studies Depression (CES-D) scale. Measurements were sought at the time of each participant’s enrolment in the study and on five subsequent occasions, the last being approximately 189 days after enrolment. The second dataset contains basic demographic information about each participant.

In summary, we have one data set containing demographic information about participants and a second data set containing measurements of two scales on happiness and depression. 

### Organising your files and project for the chapter

Before we can get started, you need to organise your files and project for the chapter, so your working directory is in order.

1. In your folder for research methods and the book `ResearchMethods1_2/Quant_Fundamentals`, create a new folder called `Chapter_04_06_datawrangling`. As we are spending three chapters on data wrangling, we will work within one folder. Within `Chapter_04_06_datawrangling`, create two new folders called `data` and `figures`.

2. Create an R Project for `Chapter_04_06_datawrangling` as an existing directory for your chapter folder. This should now be your working directory.

3. We will work within one folder, but create a new R Markdown for each chapter. Create a new R Markdown document and give it a sensible title describing the chapter, such as `04 Data Wrangling 1`. Delete everything below line 10 so you have a blank file to work with and save the file in your `Chapter_04_06_datawrangling` folder. 

4. If you already have the two files from chapter 3, copy and paste them into the `data/` folder. If you need to download them again, the links are data file one ([ahi-cesd.csv](data/ahi-cesd.csv)) and data file two ([participant-info.csv](data/participant_info.csv)). Right click the links and select "save link as", or clicking the links will save the files to your Downloads. Make sure that both files are saved as ".csv". Save or copy the file to your `data/` folder within `Chapter_04_06_datawrangling`.

You are now ready to start working on the chapter! 

::: {.callout-note collapse="true"}
#### Reminder of file management if you use the online server
If we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / RStudio to your own computer or you are using one of the library/lab computers, please ignore this section. 

1. Log on to the **R server** using the link we provided to you.

2. In the file pane, click `New folder` and create the same structure we demonstrated above.

3. Download these two data files which we used in Chapter 3. Data file one: [ahi-cesd.csv](data/ahi-cesd.csv). Data file two: [participant-info.csv](data/participant_info.csv). Save the two files into the `data` folder you created for chapter 3. To download a file from this book, right click the link and select "save link as". Make sure that both files are saved as ".csv". Do not open them on your machine as often other software like Excel can change setting and ruin the files.

4. Now that the files are stored on your computer, go to RStudio on the server and click `Upload` then `Browse` and choose the folder for the chapter you are working on.

5. Click `Choose file` and go and find the data you want to upload.
:::

### Activity 1 - Load `tidyverse` and read the data files

As the first activity, try and test yourself by loading `tidyverse` and reading the two data files. As a prompt, save the data files to these two object names to be consistent with the activities below, but you can check your answer below if you are stuck. 

```{r eval=FALSE}
# Load the tidyverse package below

# Load the two data files
# This should be the ahi-cesd.csv file 
dat <- NULL

# This should be the participant-info.csv file
pinfo <- NULL
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# Load the tidyverse package below
library(tidyverse)

# Load the two data files
# This should be the ahi-cesd.csv file 
dat <- read_csv("data/ahi-cesd.csv")

# This should be the participant-info.csv file
pinfo <- read_csv("data/participant-info.csv")
```

:::

## Tidyverse and the dplyr package

So far, we have loaded a `r glossary("package")` called `tidyverse` in every chapter and it is going to be at the core of all the data skills you develop. The `tidyverse` [https://www.tidyverse.org/](https://www.tidyverse.org/){target="_blank"} [@tidyverse] is an ecosystem containing six core packages: `dplyr`, `tidyr`, `readr`, `purrr`,  `ggplot2`, and `tibble`. Within these six core packages, you have access to `r glossary("function", display = "functions")` that will pretty much cover everything you need to wrangle and visualise your data. 

In chapter 3, we introduced you to the package `ggplot2` for data visualisation. In this chapter, we focus on functions from the [`dplyr`](https://dplyr.tidyverse.org/){target="_blank"} package, which the authors describe as a grammar of data manipulation (in the wrangling sense, not deviously making up data). 

The `dplyr` package contains several key functions based on common English verbs to help you understand what the code is doing. For an overview, we will introduce you to the following functions:

|Function|Description|
|:------:|:----------|
|`*_join()`| Add columns from two data sets by matching observations|
|`select()`| Include or exclude certain variables (columns)|
|`mutate()`| Create new variables (columns)|
|`arrange()`| Change the order of observations (rows)|
|`filter()`| Include or exclude certain observations (rows)|
|`group_by()`| Organize the observations (rows) into groups|
|`summarise()`| Create summary variables for groups of observations|

Just looking at the names gives you some idea of what the functions do. For example, `select()` selects columns and `arrange()` orders observations. You will be surprised by how far you can get with data wrangling using just these functions. There will always be unique problems to solve, but these functions cover the most common that apply to almost every data set. 

In this chapter, we focus on the `*_join()` series of functions, `select()`, `arrange()`, and `mutate()`.

## Joining two data frames with `*_join()` functions

The first thing we will do is combine data files. We have two files, `dat` and `pinfo`, but what we really want is a single file that has both the happiness and depression scores and the demographic information about the participants as it makes it easier to work with the combined data. 

To do this, we are going to use the function `inner_join()`. So far, we have described these types of functions as `*_join()`. This is because there are a series of functions that join two data sets in slightly different ways. You do not need to memorise these, but it might be useful to refer back to later. 

|Join function|Description|
|:------:|:----------|
|`inner_join()`| Keep observations in data set 1 that has a matching key in data set 2 |
|`left_join()`| Keep all observations in data set 1 |
|`right_join()`| Keep all observations in data set 2 |
|`full_join()`| Keep all observations in both data set 1 and 2 |

::: {.callout-important}
As these functions join data sets in different ways, they will produce different sample sizes depending on the presence of missing data in one or both data sets. For example, `inner_join()` will be the strictest as you must have matching observations in each data set. On the other hand, `full_join()` will be the least strict, as you retain observations that may not exist in one data set or the other. 
:::

### Activity 2 - Join the files together

We are going to join `dat` and `pinfo` by common identifiers. When we use `inner_join()`, this means we want to keep all the observations in `dat` that also has a corresponding identifier in `pinfo`. This is known as an **`r glossary("inner-join")`**, where you would exclude participants if they did not have a matching observation in one of the data sets.

The code below will create a new object, called `all_dat`, that combines the data from both `dat` and `pinfo` using the information in the columns `id` and `intervention` to match the participants' data across the two sets of data. `id` is a code or number for each unique participant and will be the most common approach you see for creating an identifier. `intervention` is the group the participant was placed in for the study by @woodworth_data_2018. 

Type and run the code in a new code chunk to inner join the two sets of data.

```{r}
all_dat <- inner_join(x = dat, 
                      y = pinfo, 
                      by = c("id", "intervention"))
```

To break down what this code is doing: 

- `all_dat` is the new object you created with the joined data. 

- `x` is the first argument and it should be the first data set / object you want to combine.

- `y` is the second argument and it should be the second data set / object you want to combine.

- `by` is the third argument and it lists the identifier as the name(s) of the column(s) you want to combine the data by in quote marks. In this scenario, there are two identifiers common to each data set. They both contain columns called "id" and "intervention". We have to wrap them in `c()` to say that there is more than one column to combine by. If there was only one common identifier, you would write `by = "id"`. 

::: {.callout-important}
#### Why does my data include .x and .y columns?

If your data sets have more than one common column, you must enter them all in the `by` argument. This tells R there are matching columns and values across the data sets. If you do not enter all the common columns, then R will add on a .x and .y when it adds them together, to label which come from each data set.

For example, try and run this code and look at the columns in `all_dat2`. You will see it has an extra column compared to `all_dat` as there is both "intervention.x" and "intervention.y". 

```{r}
all_dat2 <- inner_join(x = dat, 
                      y = pinfo, 
                      by = "id")
```
:::

### Explore your data objects

Once you have run this code, you should now see the new `all_dat` object in the environment pane. Remember to get into the habit of exploring your data and objects as you make changes, to check your wrangling is working as intended. 

There are two main ways you can do this: 

1. Click on the data object in the Environment pane. This will open it up as a tab in RStudio, and you will be able to scroll through the rows and columns (@fig-img-preview-alldat). 

::: {.callout-important}
#### Why do I not see all my columns? 

One common source of confusion is not seeing all your columns when you open up a data object as a tab. This is because RStudio shows you a maximum of 50 columns at a time. If you have more than 50 columns, to see more, you must use the arrows at the top of the tab where it says "Cols:". For example in `all_dat`, it will say 1-50, if you click the right arrow, it will then say 5-54 so you can see the final 4 columns.
:::

```{r preview-alldat, echo=FALSE}
#| label: fig-img-preview-alldat
#| fig.cap: "Exploring a data object in RStudio by opening it as a tab. You can navigate around the columns and rows without opening it up in somehthing like Excel. If there are more than 50 columns, you can click the arrows next to Cols:."

knitr::include_graphics("images/alldat_previewdata.png")

```

2. Use the `glimpse()` function to see an overview of the data objects. 

We explored this in chapter 3, but `glimpse()` tells you how many rows and columns your data have, plus an overview of responses per column. Note: you will see a preview of all 54 columns, but we have shortened it to 10 columns to take up less space in the book. 

```{r eval=FALSE}
glimpse(all_dat)
```

```{r echo=FALSE}
all_dat %>% 
  select(1:10) %>% 
  glimpse()
```

::: {.callout-tip}
#### Try this

Now you have explored `all_dat`, try and use one or both of these methods to explore the original `dat` and `pinfo` objects to see how they changed. Notice how the number of rows/observations and columns change from the original objects to when you join them. 
:::

## Selecting variables of interest with `select()`

## Arranging variables of interest with `arrange()`

## Creating or modifying variables with `mutate()`

## Six functions for wrangling the `babynames`

Ok so now we have a fairly code understanding of the babynames, let's use it to learn a bit more about the six functions from `dplyr` that make up a lot of data wrangling!

### Activity 4: Selecting variables of interest  with `select()` {#dw1-a4}

Often data has a lot of variables we don't need and it can be easier to focus on just the data we do need. In `babynames` there are two numeric measurements of name popularity - `prop`, the proportion of all babies with each name, is probably more useful than `n`, the total number of babies with that name, because `prop` takes into account that different numbers of babies are born in different years. 

Now as we saw previously, if we wanted to create a dataset that only includes certain variables, we can use the `select()` function from the `dplyr` package. 

* In a new code chunk, type and run the below code to select only the columns `year`, `sex`, `name` and `prop` and store it as a `tibble` in the object named `babynames_reduced`.
    * the first argument `.data` is the object we want to select variables from, in this case `babynames`
    * the additional arguments are the names of the variables you want to **keep**!

```{r bab-select1, eval=FALSE}
babynames_reduced1 <- select(.data = babynames,
                            year, 
                            sex, 
                            name, 
                            prop)
```

Alternatively, you can also state which variables you don't want to keep! This is really handy if you want to keep a lot of columns and only get rid of maybe one or two. 

* Type and run in the below code in a new code chunk.
    * Here, rather than stating you want to keep `year`, `sex`, `name` and `prop`, we can say drop (i.e. get rid of) the column `n` using the minus sign `-` before the variable name.

```{r bab-select2, eval=FALSE}
babynames_reduced2 <- select(.data = babynames, 
                             -n)
```

**Note** that `select()` does not change the original tibble, `babynames`, but makes a new object that stores a new tibble with the specified columns, i.e. `babynames_reduced1` and `babynames_reduced2`. You will see the new objects in your environment pane. If you don't save the new tibbles to an object, they won't be saved. For example, the below code does the same as the previous code but is not saved as the output of the function is not assigned (using the `r glossary("assignment operator")`, `<-`) to a new object. 

```{r chpt4-nosave, eval=FALSE}

select(.data = babynames, 
       -n)

```

### Activity 5: Arranging the data with `arrange()` {#dw1-a5}

Superb! We now know how to select variables. Another handy skill is being able to change the order of data in a tibble. The function `arrange()` will sort the rows in the table according to the columns you supply. 

* Type and run the below code in a new code chunk.
    * the first argument `.data` again says what object to work on
    * the second argument says what column to sort the data by - in this instance we are sorting by `name`
    * the default sorting order is ascending!

```{r sort1, eval=FALSE}

sort_asc <- arrange(.data = babynames,
                    name)

```

If you look in `sort_asc` the data are now sorted in ascending alphabetical order by name. But what if you want the data in descending order? Here we can wrap the name of the variable in the `desc()` function. 

* Type and run the below code in a new code chunk. When you have run the code have a look at `sort_desc` and note that the data is now sorted by descending year!

```{r sort2, eval=FALSE}

sort_desc <- arrange(babynames, 
                     desc(year)) 

```

Finally, you can also sort by more than one column and a combination of ascending and descending columns. Have a look at th below code and then answer the question below:

```{r sort3, eval=FALSE}

arrange(babynames, 
        desc(year), 
        desc(sex), 
        desc(prop)) 

```

The above code will produce: `r longmcq(c("the data sorted by descending year and sex but ascending prop","the data sorted by descending year and prop but ascending sex", answer = "the data sorted by descending year, sex and prop", "the data sorted by ascending year, sex and prop"))`

`r hide("Explain this answer")`
As all the columns stated are wrapped in the `desc()` function inside the `arrange()` function then all columns will be sorted in descending fashion, sorting the year first, then the sex, then the prop. Note however that the output is not being stored at all in a new object so you would not be able to work on the data later without saving it in an object first!
`r unhide()`

### Activity 7: Creating new variables with `mutate()` {#dw1-a7}

Doing really well! Only a little more to go we promise! OK so we have really learnt a lot about changing the data we have but sometimes we need to create a new variable that doesn’t exist in our dataset. For instance, we might want to figure out what decade a particular year belongs to in out babynames data and add that to our data! To create new variables, we use the function `mutate()`. 

* Type and run the below code in a new code chunk.
    * Here, you are mutating a new column onto the data and storing it in the object `baby_decades`
    * the first argument is the original data, `babynames`
    * the second argument is the name of the new column `decade` followed by what you want in that column - the decade.
    * we are creating the decades using the code `floor(year/10)*10. This seems complicated but it says take the year and divide by 10, then get rid of the decimal places, and then multiply by 10. So for example, 1945/10 = 194.5, and if you get rid of the decimal places that becomes 194, and multiply it by 10 gives you 1940s!.

```{r decades, eval = FALSE}
baby_decades <- mutate(.data = babynames,
                  decade = floor(year/10) *10)
baby_decades
```

The start of the data will look something like this with the new column called `decade` mutated on:

```{r decades-hidden, echo = FALSE}
baby_decades <- mutate(.data = babynames,
                  decade = floor(year/10) *10)
head(baby_decades)
```


But mutates can be much simpler like this example here. Have a look at the code and then answer the question below:

```{r decades2, eval = FALSE}
baby_where <- mutate(.data = babynames,
                  country = "USA")
```

What will be stored in the object `baby_where`? `r longmcq(c("a tibble with one column called country that contains the decade people were born", answer = "a tibble with all the original data and a new column called country stating USA", "a tibble with all the original data and a new column stating usa", "a tibble with all the original data arranged by the country USA"))`

`r hide("Explain this Answer")`
This code will create a new object storing a tibble that has all the original data and a new column called country that states USA for each row. The `mutate()` adds to what is already there unless you add a `select()` or `filter()` to remove columns or rows. Note that one of the answers is wrong because it states usa in lowercase but the code states it in uppercase, i.e. USA. Remember to be specific.
`r unhide()`

## Test yourself {#ld-test}

To end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter. 

### Knowledge check

1. Which of the following is not one of the Wickham Six functions? `r longmcq(c(answer = "melt()", "arrange()","mutate()","filter()"))`

2. Which of the following functions would I use if I wanted to keep only certain columns? `r longmcq(c(answer = "select()", "arrange()","mutate()","filter()"))`

3. Which of the following functions would I use if I wanted to keep only certain rows? `r longmcq(c("select()", "arrange()","mutate()",answer = "filter()"))`

4. Which of the following functions would I use if I wanted to add a new column of information? `r longmcq(c("select()", "arrange()",answer = "mutate()","filter()"))`

5. Which boolean expression would I add to a `filter()` function to keep only Male babies in the original `babynames` data? `r longmcq(c("sex == F", answer = "sex == M", "sex < F", "Sex == M"))`

`r hide("Explain these Answers")`

1. `melt()` is not a function in the Wickham six functions. It is actually a function but not one we tend to use.
2. `select()` is the function for keeping and removing columns.
3. `filter()` is the function for keeping and removing rows.
4. `mutate()` is the function for adding new columns.
5.  Assuming the original data has not been changed, `"sex == M"` would work and not `"Sex == M"` as there is no column called Sex with an uppercase S. Remember to be exact.
`r unhide()`

### Error mode

The following questions are designed to introduce you to making and fixing errors. For this topic, we focus on reading data and using ggplot2. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently. 

Create and save a new R Markdown file for these activities by following the instructions in Chapter 2. You should have a blank R Markdown file below line 10. Below, we have several variations of a code chunk and inline code errors. Copy and paste them into your R Markdown file, click knit, and look at the error message you receive. See if you can fix the error and get it working before checking the answer.

1. Restart the R session (**`Session >> Restart R`**). Make sure that the working directory is set to the right folder and then run the below code in your console window:

```{r debugging1, eval = FALSE}
babynames
```

This will produce the error:

```
Error: object 'babynames' not found
```

Once you figure out how to fix this error, make a note of it.

`r hide("Solution")`
This is an indication that you have not loaded the `babynames` package into the library using the `library()` function
`r unhide()`
<br>

2. Restart the R session (**`Session >> Restart R`**). Make sure that the working directory is set to the right folder and then run the below code in your console window:

```{r debugging2, eval = FALSE}
library(babynames)

dat <- summarise(.data = babynames, mean_n = mean(n))
```

This will produce the error:

```
Error in summarise(.data = babynames, mean_n = mean(n)) : 
  could not find function "summarise"
```

Once you figure out how to fix this error, make a note of it.

`r hide("Solution")`
What the error is saying is that there is no function called `summarise()`. You know that function exists though. What you have not done is call load the function into the libary using `library(tidyverse)`
`r unhide()`
<br>

3. Restart the R session (**`Session >> Restart R`**). Make sure that the working directory is set to the right folder and then run the below code in your console window:

```{r debugging3, eval = FALSE}
library(babynames)
library(tidyverse)

dat <- summarise(.data = babynames mean_n = mean(n))
```

This will produce the error:

```
Error: unexpected symbol in "dat <- summarise(.data = babynames mean_n"

```
Once you figure out how to fix this error, make a note of it.

`r hide("Solution")`
This is actually one of the most painful errors you can see as it doesn't really help you solve your issue because it is not quite clear what it means. **unexpected symbol** means effectively that the code is wrong and it is seeing something it did not think it would see. Again not that clear right? What we do when we see this is ask ourselves have we forgotten a comma somewhere or maybe a bracket or a quotation mark! Look for those issues and see if that helps. The error does show you that the error comes between `babynames` and `mean_n` it just isn't clear that that is what it means. The issue will be around the last word it mentions basically. The answer here is that there is a comma missing between the data and the arguement; between `babynames` and `mean_n`. The line should read: 

```{r debugging4, eval = FALSE}
library(babynames)
library(tidyverse)

dat <- summarise(.data = babynames, mean_n = mean(n))
```

Again an incredibly frustrating and time consuming error. Watch out for these. It is why partitioning the code on to new lines after a comma can be really help see errors as such:

```{r debugging5, eval = FALSE}
library(babynames)
library(tidyverse)

dat <- summarise(.data = babynames, 
                 mean_n = mean(n))
```

Such a dastardly error! Well done if you spotted it!!!

`r unhide()`
<br>

## Words from this Chapter

Below you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the [PsyTeachR Glossary](https://psyteachr.github.io/glossary/){target="_blank"}. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.

```{r gloss, echo=FALSE, results='asis'}
glossary_table()
```

## End of Chapter

That is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!

Brilliant! That has been a lot of information but hopefully it has started to give you a sense of some of the approaches to data wrangling and the main functions we will use as we get deeper into the book! 
