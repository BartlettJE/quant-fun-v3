# Data wrangling 2: Filter and summarise {#05-wrangling-2}

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load the tidyverse package below
library(tidyverse)

# Load the data file
# This should be the witt_2018.csv file 
pong_data <- read_csv("data/witt_2018.csv")

```

As we have said previously, one of the key aspects in a researcher's toolbox is the knowledge and skill to work with data - regardless of how it comes to you. In fact, when you run an experiment you might get lots of different data types in various different files. For instance, it is not uncommon for an experimental software to create a new file for every participant you run and for each participant's file to contain numerous columns and rows of different data types, only some of which are important. Being able to wrangle that data, manipulate it into different layouts, extract the parts you need, and summarise it, is one of the most important skills we will help you learn through this book.

In the last chapter we introduced you to the **Wickham six** one-table `r glossary("function", display = "functions")` which we use to do that data wrangling. Over the course of this book we will reiterate these functions and skills, and `r glossary("package", display = "packages")` like the `tidyverse` and the packages it contains, across a number of different datasets to give you a wide range of exposure to what Psychology is about, and to reiterate that the same skills apply across different datasets. Always remember, **the whilst the data changes, the skills stay the same!**

Today, we are going to continue developing our understanding of data, and build on the knowledge and skills we have seen to this point, to help you develop your ability to work with data. The only difference in this chapter is we are going to ask you to do more of the wrangling yourself, based on what we have shown you previously. To build our skills we will analyse a novel dataset and some activities based around manipulating that data. Remember to be pro-active in your learning and to refer back to what we have done before, using the example code as a guide. The solutions for all the tasks are at the bottom of the page as well for you to check yourself, but do be sure to try the tasks first. There is also the online [cheatsheets](https://www.rstudio.com/resources/cheatsheets/){target="_blank"} if you need more help - the key cheatsheet for this chapter is the Data Transformation with **`dplyr`**  -  and don't forget to ask questions on ours forums.

**Chapter Intended Learning Outcomes (ILOs)**

By the end of this chapter, you will be able to: 

- ILO1

## Chapter preparation

### Introduction to the data set 

For this chapter, we are using open data from @witt2018. The abstract of their article is:

> Can one’s ability to perform an action, such as hitting a softball, influence one’s perception? According to the action-specific account, perception of spatial layout is influenced by the perceiver’s abilities to perform an intended action. Alternative accounts posit that purported effects are instead due to nonperceptual processes, such as response bias. Despite much confirmatory research on both sides of the debate, researchers who promote a response-bias account have never used the Pong task, which has yielded one of the most robust action-specific effects. Conversely, researchers who promote a perceptual account have rarely used the opposition’s preferred test for response bias, namely, the postexperiment survey. The current experiments rectified this. We found that even for people naive to the experiment’s hypothesis, the ability to block a moving ball affected the ball’s perceived speed. Moreover, when participants were explicitly told the hypothesis and instructed to resist the influence of their ability to block the ball, their ability still affected their perception of the ball’s speed. 

To summarise, their research question was: **does your ability to perform an action influence your perception?** For instance, does your ability to hit a tennis ball influence how fast you perceive the ball to be moving? Or to phrase another way, do expert tennis players perceive the ball moving slower than novice tennis players?  

This experiment does not use tennis players, instead they used the Pong task like the classic retro arcade game. Participants aimed to block moving balls with various sizes of paddles. Participants tend to estimate the balls as moving faster when they have to block it with a smaller paddle as opposed to when they have a bigger paddle. In this chapter, we will wrangle their data to reinforce skills from Chapter 4, and add more <pkg>dplyr</pkg> functions to your toolkit. 

### Organising your files and project for the chapter

Before we can get started, you need to organise your files and project for the chapter, so your working directory is in order.

1. In your folder for research methods and the book `ResearchMethods1_2/Quant_Fundamentals`, you should have a folder from chapter 4 called `Chapter_04_06_datawrangling`.

2. Create a new R Markdown document and give it a sensible title describing the chapter, such as `05 Data Wrangling 2`. Delete everything below line 10 so you have a blank file to work with and save the file in your `Chapter_04_06_datawrangling` folder. 

4. We are working with a new data set, so please save the following data file: ([witt_2018.csv](data/witt_2018.csv). Right click the link and select "save link as", or clicking the link will save the files to your Downloads. Make sure that both files are saved as ".csv". Save or copy the file to your `data/` folder within `Chapter_04_06_datawrangling`.

You are now ready to start working on the chapter! 

## Select, arrange, and mutate recap

Before we introduce you to new functions, we will recap data wrangling functions from chapter 3 to select, arrange, and mutate. Following along is one thing but being able to transfer your understanding to a new data set is a key sign of your skill development. Feel free to use chapter 3 to help you, but try and complete the recap activities independently before checking the solutions. This will help prepare you as we move from the chapters, to the data analysis journeys, to the assessments, and to your future career. 

### Activity 1 - Load <pkg>tidyverse</pkg> and read the data files

As the first activity, try and test yourself by loading <pkg>tidyverse</pkg> and reading the data file. As a prompt, save the data file to this object name to be consistent with the activities below, but you can check your answer below if you are stuck. 

```{r eval=FALSE}
# Load the tidyverse package below
?
  
# Load the data file
# This should be the witt_2018.csv file 
pong_data <- ?
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# Load the tidyverse package below
library(tidyverse)

# Load the data file
# This should be the witt_2018.csv file 
pong_data <- read_csv("data/witt_2018.csv")
```

:::

### Activity 2 - Explore `pong_data`

Remember the first critical step when you come across any new data is exploring to see how many columns you are working with, how many rows/observations there are, and what the values look like. For example, you can click on `pong_data` in the environment and scroll around it as a tab. You can also get a preview of your data by using the `glimpse()` function. 

```{r}
glimpse(pong_data)
```

If you look at that table, you can see there are 8 columns and 4608 rows. Seven of the column names are `<dbl>`, short for double, and one is `<chr>` short for character. We will need to keep the data types in mind as we wrangle the data. 

### Data types in R 

We try and balance developing your data skills in a practical way while slowly introducing some of the underlying technical points. In the last chapter, we warned about honoring data types so R knew how to handle numbers/doubles vs factors. Now we have explored a few data sets, it is time to clarify some key differences between data types in R. 

We often store data in two-dimensional tables, either called `r glossary("data frame", display = "data frames")`, tables, or `r glossary("tibble", display = "tibbles")`. There are other ways of storing data that you will discover in time but in this book, we will be using data frame or tibbles (a special type of data frame in the tidyverse). A data frame is really just a table of data with columns and rows of information. Within the cells of the data frame - a cell being where a row and a column meet - you get different types of data, including `r glossary("double")`, `r glossary("integer")`, `r glossary("character")` and `r glossary("factor")`. To summarise: 

|Type of Data | Description                                                  |
|:------------|:-------------------------------------------------------------| 
|Double       | Numbers that can take decimals                               |
|Integer      | Numbers that cannot take decimals                            |
|Character    | Tends to contain letters or be words                         |
|Factor       | Nominal (categorical). Can be words or numbers (e.g., animal or human, 1 or 2)|

Double and Integer can both be referred to as `r glossary("numeric")` data, and you will see this word from time to time. For clarity, we will use Double as a term for any number that can take a decimal (e.g. 3.14) and Integer as a term for any whole number (no decimal, e.g. 3).

Somewhat confusingly, Double data might not have decimal places in it. For instance, the value of 1 could be Double as well as Integer. However, the value of 1.1 could only be Double and never Integer. Integers cannot have decimal places. The more you work with data the more this will make sense, but it highlights the importance of looking at your data and checking what type it is as the type determines what you can do with the data.

In `pong_data`, each row (observation) represents one trial per participant and that there were 288 trials for each of the 16 participants. Most of the data is a double (i.e., numbers) and one column is a `character` (i.e., text). The columns (variables) we have in the data set are:

| Variable       |       Type                       |           Description          |
|:--------------:|:---------------------------------|:-------------------------------|
| Participant    | `r typeof(pong_data$Participant)`| participant number             |
| JudgedSpeed    | `r typeof(pong_data$JudgedSpeed)`| speed judgement (1 = fast, 0 = slow)|
| PaddleLength   | `r typeof(pong_data$PaddleLength)`| paddle length (pixels)        |
| BallSpeed      | `r typeof(pong_data$BallSpeed)`  | ball speed (2 pixels/4ms)      |
| TrialNumber    | `r typeof(pong_data$TrialNumber)`| trial number                   |
| BackgroundColor| `r typeof(pong_data$BackgroundColor)`| background display colour  |
| HitOrMiss      | `r typeof(pong_data$HitOrMiss)`  | hit ball = 1, missed ball = 0      |
| BlockNumber    | `r typeof(pong_data$BlockNumber)`| block number (out of 12 blocks)|

### Activity 3 - `select()` a range of columns {#dw2-a3}

Either by inclusion (stating all the variables you want to keep) or exclusion (stating all the variables you want to drop), create a new object named `select_dat` and select the following columns from `pong_data`:

- `Participant`

- `PaddleLength`

- `TrialNumber`

- `BackgroundColor`

- `HitOrMiss`

```{r eval=FALSE}
# select 5 variables from pong_data
select_dat <- ?
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# select 5 variables from pong_data
select_dat <- select(pong_data,
                     Participant,
                     PaddleLength,
                     TrialNumber,
                     BackgroundColor,
                     HitOrMiss)
```

:::

### Activity 4 - Reorder the variables using `select()` {#dw2-a4}

We can also use `select()` to reorder your columns, as the new data object will display the variables in the order that you entered them. 

Use `select()` to keep only the columns `Participant`, `JudgedSpeed`, `BallSpeed`, `TrialNumber`, and `HitOrMiss` from `pong_data` but this time, display them in ascending alphabetical order. Save this tibble in a new object named `reorder_dat`.

```{r eval=FALSE}
# reorder the 5 variables from pong_data
reorder_dat <- ?
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# reorder the 5 variables from pong_data
reorder_dat <- select(pong_data, # original data
                     BallSpeed,
                     HitOrMiss,
                     JudgedSpeed,
                     Participant,
                     TrialNumber)
```

:::

### Activity 5 - Reorder observations using `arrange()` {#dw2-a5}

Reorder observations in the data using the following two variables: `HitOrMiss` (putting hits (1) first) and `JudgedSpeed` (putting fast judgement () first). Store this in an object named `arrange_dat`. 

```{r eval=FALSE}
# arrange pong_data by HitOrMiss and JudgedSpeed
arrange_dat <- ?
```

Now try and answer the following questions about the data.

1. What is the trial number (`TrialNumber`) in the 1st row? `r fitb(5)`

2. What is the background colour (`BackgroundColor`) in the 10th row? `r fitb("blue")`

::: {.callout-tip collapse="true"}
#### Show me the solution
You needed to include `desc()` to change it from running smallest-to-largest to largest-to-smallest as the values are 0 and 1. You should have the following in a code chunk: 

```{r eval=FALSE}
# arrange pong_data by HitOrMiss and JudgedSpeed
arrange_dat <- arrange(pong_data, # original data
                     desc(HitOrMiss),
                     desc(JudgedSpeed))
```

:::

### Activity 6 - Modify or creating variables using `mutate()` {#dw2-a7}

Some of these values could be a little easier to understand. They are represented in the data by 0s and 1s, but it might not be immediately obvious what they mean. 

Using what you learnt in Chapter 4 about modifying existing variables, create a new variable called `JudgedSpeedLabel` by mutating the original `pong_data` object. Change the values in `JudgedSpeed` using the following labels: 

0 = Slow

1 = Fast

```{r eval=FALSE}
# mutate pong_data and recode values into a new variable
pong_data <- ?
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r}
# mutate pong_data and recode values into a new variable
pong_data <- mutate(pong_data, 
                    JudgedSpeedLabel = case_match(JudgedSpeed, 
                                                  0 ~ "Slow",
                                                  1 ~ "Fast"))
```

:::

## Removing or retaining observations using `filter()`

Now we have revisited key data wrangling functions from Chapter 4 to select, arrange, and mutate, it is time to add some new functions from <pkg>dplyr</pkg> to your toolkit. 

Using select, we could remove columns, but there are many situations where you want to include or exclude certain observations/rows. The function `r glossary("filter()", def = "The ability to subset a data frame to keep all observations/rows that satisfy one or more conditions.")` will possibly be one of your most used for data wrangling. For example, imagine you want to only analyse participants who provided informed consent and exclude participants who did not. Similarly, you might want to focus your analyses only on participants who are under the age of 21. 

### Activity 7 - Filter using one criterion 

We will jump straight into an example. Imagine that you realised you made a mistake creating your experiment and all your trial numbers are wrong. The first trial (trial number 1) was a practice, so you should exclude it and your experiment actually started on trial 2.

```{r}
pong_data_filter <- filter(pong_data,
                           TrialNumber > 1)
```

To break down the code:

- We create a new object called `pong_data_filter` by applying the filter function to `pong_data`.

- We add the Boolean expression `TrialNumber > 1` to keep all responses higher than 1 (i.e., 2 or higher). 

The `filter()` function uses our old friends the Boolean expressions we introduced you to in Chapter 4. You can add one or more logical expressions to filter observations. The function retains observations when they are evaluated to TRUE and ignores observations when they are evaluated to FALSE. Remember, when you are working out how to express your ideas in code, test them out. For example, we can see what the expression would do to different trial numbers: 

```{r}
1 > 1

2 > 1
```

1 is not larger than 1, so it's evaluated to FALSE and would be ignored. 2 is larger than 2, so it's evaluated to TRUE and would be retained. Explore the two data sets `pong_data` and `pong_data_filter` and the number of rows they have to see the effects of applying the function. 

As a reminder from Chapter 4, the most common Boolean expressions are: 

Operator	|Name	                 |is TRUE if and only if
----------|----------------------|---------------------------------
A < B 	  |less than 	           |A is less than B
A <= B 	  |less than or equal    |A is less than or equal to B
A > B 	  |greater than 	       |A is greater than B
A >= B 	  |greater than or equal |A is greater than or equal to B
A == B 	  |equivalence 	         |A exactly equals B
A != B 	  |not equal 	           |A does not exactly equal B
A %in% B 	|in 	                 |A is an element of vector B

::: {.callout-tip}
#### Try this
Using the `filter()` example and the table above, imagine we wanted to only keep trials where participants' judged the speed to be "Fast". Use the `pong_data_filter` after removing trial number 1 and assign it to a new object `pong_data_fast`. You could use the `JudgedSpeed` or `JudgedSpeedLabel` variables to do this. 

For a hint, you want to keep responses when they are equivalent to "Fast" or 1 depending on the variable you use. 

```{r eval=FALSE}
# Retain fast judged speed trials
pong_data_fast <- filter(pong_data_filter,
                         ?)
```

:::

::: {.callout-caution collapse="true"} 
#### Solution
You were looking for the equivalence Boolean operator (==) to retain responses which were equal to "Fast" or 1. If you used `JudgedSpeedLabel`, you should have:

```{r eval=FALSE}
# Retain fast judged speed trials
pong_data_fast <- filter(pong_data_filter,
                         JudgedSpeedLabel == "Fast")
```

If you used `JudgedSpeed`, you should have:

```{r eval=FALSE}
# Retain fast judged speed trials
pong_data_fast <- filter(pong_data_filter,
                         JudgedSpeedLabel == 1)
```

Note we use a double equals == and not a single equals = for the Boolean operator. We also must honour the data type for the expression we set. 
:::

### Activity 8 - Filter using two or more criteria 

You explored using one criterion to filter out or retain observations/rows, but you can make the expressions arbitrarily more complicated by adding two or more criteria to evaluate against. Just note the more criteria you add, the more selective you are being. You are probably going to be excluding more and more observations, so think about what you want to achieve. 

Focusing on one variable, you can specify multiple values to compare against. For example, you might want to only keep responses which had a ball speed of 2 or 4:

```{r}
pong_data_BallSpeed <- filter(pong_data_filter,
                              BallSpeed == 2 | BallSpeed == 4)
```

To break down the code:

- We create a new object called `pong_data_BallSpeed` by applying the filter function to `pong_data_filter`.

- We add the Boolean expression `BallSpeed == 2`, the vertical line symbol (`|`), then a second expression `BallSpeed == 4`. The vertical line symbol (`|`) means "or", so our expression is retain `BallSpeed` responses which equal 2 OR 4, and ignore all the others. 

For two values, this is pretty straightforward, but it could get out of hand when you have four or five values to evaluate against. There is a super handy shortcut from the Boolean expressions table for "in" which we can apply if we wanted to keep ball speeds of 2, 4, 5, and 7:

```{r}
pong_data_BallSpeed <- filter(pong_data_filter,
                              BallSpeed %in% c(2, 4, 5, 7))
```

You can read the expression here as: for each observation/row, check whether the value of `BallSpeed` is in the vector of numbers 2, 4, 5, 7. Remember `filter()` works by whether the expression is evaluted to TRUE or FALSE, so you can see how it works by testing some numbers: 

```{r}
1 %in% c(2, 4, 5, 7)
2 %in% c(2, 4, 5, 7)
```

1 is not present in `c(2, 4, 5, 7)`, so it is evaluated to FALSE and would be ignored. 2 is presented in `c(2, 4, 5, 7)`, so it is evaluated to TRUE and would be retained. 

You can also add two or more expressions including multiple variables by adding them to the function separated by commas. For example, imagine we wanted to retain observations/rows which had a "Fast" speed judgement with ball speeds of 2, 4, 5, and 7:

```{r}
pong_fast_BallSpeed <- filter(pong_data_filter, 
                         JudgedSpeedLabel == "Fast", 
                         BallSpeed %in% c("2", "4", "5", "7"))
```

In the first expression, we only want to keep observations/rows which have a `JudgedSpeedLabel` of "Fast". In the second expression, we only want to keep observations/rows which have a BallSpeed of 2, 4, 5, or 7. In other words, retain "Fast" observations AND those with a ball speed of 2, 4, 5, or 7. Adding more expressions makes your criteria more selective as rows must pass both conditions to be retained in the data. 

::: {.callout-tip}
#### Try this
Using the examples above, imagine we wanted to only keep trials where:

1. The `PaddleLength` is 50. 

2. The `BackgroundColor` is red.

3. The `HitOrMiss` is 1. 

Use the `pong_data_filter` object and assign it to a new object `pong_data_three_criteria`.

```{r eval=FALSE}
# apply three criteria to filter pong_data_filter
pong_data_three_criteria <- filter(pong_data_filter,
                                   ?)
```

:::

::: {.callout-caution collapse="true"} 
#### Solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# apply three criteria to filter pong_data_filter
pong_data_three_criteria <- filter(pong_data_filter,
                                   PaddleLength == 50,
                                   BackgroundColor == "red",
                                   HitOrMiss == 1)
```

:::

## Counting observations using `count()`

First we want to look at different ways of counting your observations. Often it is helpful to know how many observations you have, either in total, or broken down by groups. This can help you spot if something has gone wrong in a calculation, for example, if you've done something with the code and your mean or median is only being calculated using a subset of the values you intended.

There are two ways of counting the number of observations. The first uses `summarise()` and the function `n()` within the `summarise()`. For example, the below code is the same as the previous activity, but with an extra line that will add a column called `n` to the table that contains the number of observations in each group. This is useful for when you want to add a column of counts to a table of other descriptive statistics. 

* **Note:** the function is `n()` and takes no arguments it is just left blank as shown, `n()`.  However, as in other functions, the `n` prior to the `=` could be called anything you want the column to be called, e.g. `n = n()` or `number = n()` would do the same but just give different names to the column.

```{r showing-n, message = FALSE}
pong_count <- pong_data_filter %>% 
  group_by(BackgroundColor, 
           PaddleLength) %>% 
  summarise(total_hits = sum(HitOrMiss, 
                             na.rm = TRUE),
            meanhits = mean(HitOrMiss, 
                            na.rm = TRUE),
            n = n())
```

However, if you're just interested in counts rather than also calculating descriptives, this above method is a bit clunky. Instead, we can use the function `count()` which is specifically designed to count observations and doesn't require the use of `summarise()` or `group_by()`.

To count the total number of observations in the dataset for example we would do:

```{r count1, eval = FALSE}
pong_data %>% # take pong_data
  count() # and then count the observations in it
```

And it would give the answer of:

```{r count2, echo = FALSE}
pong_data %>% count()
```

Alternatively, to count the number of observations in each level of a variable you could do:

```{r count3, eval = FALSE}
pong_data %>%
  count(BackgroundColor)
```

And it would give the answer of:

```{r count4, echo = FALSE}
pong_data %>%
  count(BackgroundColor)
```

Which method you use will depend on whether you want to add the counts to a table of other descriptives, but both functions are useful to know.

## Getting summary statistics using `summarise()` and `group_by()`

Excellent! And now that we have done some wrangling we want to calculate some descriptive statistics for the data using `summarise()`. `summarise()` has a range of internal functions that make life really easy, e.g. `mean`, `sum`, `max`, `min`, etc. See the [dplyr cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) for more examples. And additional one that we will use from time-to-time is `na.rm = TRUE` which we can add when calculating descriptive statistics to say what to do if there are missing values. Missing values often appear as `NA` and the job of `na.rm` is to say whether to remove (rm) the NAs (`na.rm = TRUE`) or not (`na.rm = FALSE`). If you try to calculate values from data that have NAs, such as the mean, it would return `NA` as the result because it doesn't know how to average nothing. This dataset has no missing values but we will show you how to use it here and try to remember this argument exists, as you will use it often and it save you a lot of time!

Back to the activity. Here, using the data in `pong_data_renumbered` we will calculate:

* The total (sum) number of hits for each combination of background colour and paddle length.
* The mean number of hits for each combination of background colour and paddle length

Remember though, because we want to produce descriptive statistics by groups (background colour and paddle length), there are two steps:

* First we group the data by `BackgroundColor` and `PaddleLength` using `group_by()`.
* Then, we use `summarise()` to calculate the total and mean number of hits (`HitOrMiss`) using the grouped data

We will do this activity using pipes to reduce the amount of code we write. Remember to try and read the code out loud and to pronounce `%>%` as 'and then'. Copy and paste the below code into a new code chunk and run the code.

```{r act8-hide, echo=FALSE}
pong_data_renumbered <- filter(pong_data, 
                               TrialNumber >= 2) %>%
  mutate(TrialNumber = TrialNumber - 1)
```

```{r datasummary, eval = TRUE}
pong_data_hits <- pong_data_renumbered %>% 
  group_by(BackgroundColor, 
           PaddleLength) %>% 
  summarise(total_hits = sum(HitOrMiss, 
                             na.rm = TRUE),
            meanhits = mean(HitOrMiss, 
                            na.rm = TRUE))
```

```{block, type = "info"}
Remember, if you get what looks like an error that says "`summarise()` has grouped output by 'BackgroundColor'. You can override using the `.groups` argument.", don't worry, this isn't an error it's just the code telling you how the final object is grouped.
```

* View `pong_data_hits` and answer the following questions to see if you have completed the task correctly.

```{r mcq-ans1, echo = FALSE}
act8_correct <- pong_data_hits %>% 
  filter(BackgroundColor == "blue", 
         PaddleLength == 50) %>% 
  pull(total_hits)
act8_false1 <- pong_data_hits %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 50) %>% 
  pull(total_hits)
act8_false2 <- pong_data_hits %>% 
  filter(BackgroundColor == "blue", 
         PaddleLength == 250) %>% 
  pull(total_hits)
act8_false3 <- pong_data_hits %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 250) %>%
  pull(total_hits)
```

* What was the total number of hits made with the small paddle (50) and the blue colour background? `r longmcq(sample(c(answer = act8_correct,act8_false3,act8_false2,act8_false1)))`

```{r mcq-ans2, echo = FALSE}
act8_correct <- pong_data_hits %>% 
  filter(BackgroundColor == "blue", 
         PaddleLength == 50) %>% 
  pull(meanhits) %>%
  round(3)
act8_false1 <- pong_data_hits %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 50) %>% 
  pull(meanhits) %>%
  round(3)
act8_false2 <- pong_data_hits %>% 
  filter(BackgroundColor == "blue", 
         PaddleLength == 250) %>% 
  pull(meanhits) %>%
  round(3)
act8_false3 <- pong_data_hits %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 250) %>%
  pull(meanhits) %>%
  round(3)
```

* To three decimal places, what was the mean number of hits made with the small paddle (50) and the blue colour background? `r longmcq(sample(c(answer = act8_correct,act8_false3,act8_false2,act8_false1)))`

**Note:**

* The name of the column within `pong_data_hits` is `total_hits`; this is what you called it in the above code. You could have called it anything you wanted but always try to use something sensible.
* Make sure to call your variables something you (and anyone looking at your code) will understand and recognize later (i.e. not variable1, variable2, variable3. etc.), and avoid spaces (use_underscores_never_spaces). 

### Counting data {#dw2-a9}

### Ungrouping data {#dw2-ungroup}

After grouping data together using the `group_by()` function and then performing a task on it, e.g. `filter()`, it can be very good practice to ungroup the data before performing another function - by piping it into the `ungroup()` function - this is related to what the warnings about `summarise()` mean as they are changing the groupings so removing all groupings can be good to do. Forgetting to ungroup the dataset won't always affect further processing, but can really mess up other things. Again just a good reminder to always check the data you are getting out of a function a) makes sense and b) is what you expect.

This is an example of how you might use the function:

```{r ungroup1, eval = FALSE}
pong_data_ungroup <- pong_data %>%
  group_by(BackgroundColor, 
           PaddleLength) %>%
  summarise(total_hits = sum(HitOrMiss)) %>%
  ungroup
```

## Test yourself

To end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter. 

### Knowledge check

1. What type of data would these most likely be:

* Male = `r mcq(c(answer = "Character","Numeric","Integer"))`

* 7.15 = `r mcq(c("Character",answer = "Double","Integer"))`

* 137 = `r mcq(c("Character","Double",answer = "Integer"))`

`r hide("Explain these answers")`
```{r, echo = FALSE, results='asis'}
cat("
There is a lot of different types of data and as well as different types of levels of measurements and it can get very confusing. It's important to try to remember which is which because you can only do certain types of analyses on certain types of data and certain types of measurements. For instance, you can't take the average of Characters just like you can't take the average of Categorical data. Likewise, you can do any maths on Double data, just like you can on Interval and Ratio data. Integer data is funny in that sometimes it is Ordinal and sometimes it is Interval, sometimes you should take the median, sometimes you should take the mean. The main point is to always know what type of data you are using and to think about what you can and cannot do with them.

* Note that the last answer, 137, could also be double as it isn't clear if it could take a decimal or not. 
")
```
`r unhide()`

<br>

2. Which of the Wickham Six would you use to sort columns from smallest to largest: `r longmcq(c("select","filter","mutate",answer ="arrange","group_by","summarise"))`
3. Which of the Wickham Six would you use to calculate the mean of a column: `r longmcq(c("select","filter","mutate","arrange","group_by",answer ="summarise"))`
4. Which of the Wickham Six would you use to remove certain observations - e.g. remove all males: `r longmcq(c("select",answer = "filter","mutate","arrange","group_by","summarise"))` 
5. What does this line of code say? `data %>% filter() %>% group_by() %>% summarise()`: `r longmcq(c("take the data and then group it and then filter it and then summarise it", answer = "take the data and then filter it and then group it and then summarise it", "take the data and then summarise it and then filter it and then group it","take the data and then group it and then summarise it and then filter it"))`  

### Error mode

The following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using the functions `inner_join()`, `select()`, and `mutate()`. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently. 

Create and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load `tidyverse` and the two data files: 

- filter using equals not double equals

### Debugging tips {#dw2-debug}

There are no debugging challenges today as we have done a lot of work but here are some tips to keep in mind.

* Remember to run the library and not just write the code
* Make sure you have spelt the data file name **exactly** as it is shown. Spaces and everything. Do not change the name of the csv file, fix your code instead. If you have a different name for your file than someone else then your code is not reproducible.
* Remember when uploading data we use `read_csv()` which has an underscore, whereas the data file itself will have a dot in its name, `filename.csv`. 
* Check that the datafile is actually in the folder you have set as your working directory. 
* Remember to start a new session each time you start a new analysis - the more functions and packages you use the great a chance of conflicting functions. 
* Watch the spelling of functions and remember to put the data first. Often people forget to include the data as they are focussing on what they want to do.
* Always look at the output of your functions as you build the code. Often code runs but it doesn't do what you think it is doing because you wrote the code wrong. Code only does what you tell it to do!
* When using pipes, remember that you only need the data once, at the start.
* If separating pipes across different lines, remember the line ends with the pipe, it does not start with the pipe.
* And lastly, remember that only the data changes, the skills stay the same. Always look back to when you had the code working and go from there.

## Words from this Chapter

Below you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the [PsyTeachR Glossary](https://psyteachr.github.io/glossary/){target="_blank"}. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.

```{r gloss, echo=FALSE, results='asis'}
glossary_table()
```

## End of chapter

That is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!

Brilliant work again! We have now learned a number of functions and verbs that you will need as you progress through this book.  You will use them in the next chapter so be sure to go over these and try them out to make yourself more comfortable with them.  If you have any questions please post them on Teams. **Happy Wrangling!**



