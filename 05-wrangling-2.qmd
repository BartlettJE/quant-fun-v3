# Data wrangling 2: Filter, summarise, and pipes {#05-wrangling-2}

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load the tidyverse package below
library(tidyverse)

# Load the data file
# This should be the witt_2018.csv file 
pong_data <- read_csv("data/witt_2018.csv")

```

As we have said previously, one of the key aspects in a researcher's toolbox is the knowledge and skill to work with data - regardless of how it comes to you. In fact, when you run an experiment you might get lots of different data types in various different files. For instance, it is not uncommon for an experimental software to create a new file for every participant you run and for each participant's file to contain numerous columns and rows of different data types, only some of which are important. Being able to wrangle that data, manipulate it into different layouts, extract the parts you need, and summarise it, is one of the most important skills we will help you learn through this book.

In the last chapter we introduced you to the **Wickham six** one-table `r glossary("function", display = "functions")` which we use to do that data wrangling. Over the course of this book we will reiterate these functions and skills, and `r glossary("package", display = "packages")` like the `tidyverse` and the packages it contains, across a number of different datasets to give you a wide range of exposure to what Psychology is about, and to reiterate that the same skills apply across different datasets. Always remember, **the whilst the data changes, the skills stay the same!**

Today, we are going to continue developing our understanding of data, and build on the knowledge and skills we have seen to this point, to help you develop your ability to work with data. The only difference in this chapter is we are going to ask you to do more of the wrangling yourself, based on what we have shown you previously. To build our skills we will analyse a novel dataset and some activities based around manipulating that data. Remember to be pro-active in your learning and to refer back to what we have done before, using the example code as a guide. The solutions for all the tasks are at the bottom of the page as well for you to check yourself, but do be sure to try the tasks first. There is also the online [cheatsheets](https://www.rstudio.com/resources/cheatsheets/){target="_blank"} if you need more help - the key cheatsheet for this chapter is the Data Transformation with **`dplyr`**  -  and don't forget to ask questions on ours forums.

**Chapter Intended Learning Outcomes (ILOs)**

By the end of this chapter, you will be able to: 

- ILO1

## Chapter preparation

### Introduction to the data set 

For this chapter, we are using open data from @witt2018. The abstract of their article is:

> Can one’s ability to perform an action, such as hitting a softball, influence one’s perception? According to the action-specific account, perception of spatial layout is influenced by the perceiver’s abilities to perform an intended action. Alternative accounts posit that purported effects are instead due to nonperceptual processes, such as response bias. Despite much confirmatory research on both sides of the debate, researchers who promote a response-bias account have never used the Pong task, which has yielded one of the most robust action-specific effects. Conversely, researchers who promote a perceptual account have rarely used the opposition’s preferred test for response bias, namely, the postexperiment survey. The current experiments rectified this. We found that even for people naive to the experiment’s hypothesis, the ability to block a moving ball affected the ball’s perceived speed. Moreover, when participants were explicitly told the hypothesis and instructed to resist the influence of their ability to block the ball, their ability still affected their perception of the ball’s speed. 

To summarise, their research question was: **does your ability to perform an action influence your perception?** For instance, does your ability to hit a tennis ball influence how fast you perceive the ball to be moving? Or to phrase another way, do expert tennis players perceive the ball moving slower than novice tennis players?  

This experiment does not use tennis players, instead they used the Pong task like the classic retro arcade game. Participants aimed to block moving balls with various sizes of paddles. Participants tend to estimate the balls as moving faster when they have to block it with a smaller paddle as opposed to when they have a bigger paddle. In this chapter, we will wrangle their data to reinforce skills from Chapter 4, and add more <pkg>dplyr</pkg> functions to your toolkit. 

### Organising your files and project for the chapter

Before we can get started, you need to organise your files and project for the chapter, so your working directory is in order.

1. In your folder for research methods and the book `ResearchMethods1_2/Quant_Fundamentals`, you should have a folder from chapter 4 called `Chapter_04_06_datawrangling`.

2. Create a new R Markdown document and give it a sensible title describing the chapter, such as `05 Data Wrangling 2`. Delete everything below line 10 so you have a blank file to work with and save the file in your `Chapter_04_06_datawrangling` folder. 

4. We are working with a new data set, so please save the following data file: ([witt_2018.csv](data/witt_2018.csv). Right click the link and select "save link as", or clicking the link will save the files to your Downloads. Make sure that both files are saved as ".csv". Save or copy the file to your `data/` folder within `Chapter_04_06_datawrangling`.

You are now ready to start working on the chapter! 

## Select, arrange, and mutate recap

Before we introduce you to new functions, we will recap data wrangling functions from chapter 3 to select, arrange, and mutate. Following along is one thing but being able to transfer your understanding to a new data set is a key sign of your skill development. Feel free to use chapter 3 to help you, but try and complete the recap activities independently before checking the solutions. This will help prepare you as we move from the chapters, to the data analysis journeys, to the assessments, and to your future career. 

### Activity 1 - Load <pkg>tidyverse</pkg> and read the data files

As the first activity, try and test yourself by loading <pkg>tidyverse</pkg> and reading the data file. As a prompt, save the data file to this object name to be consistent with the activities below, but you can check your answer below if you are stuck. 

```{r eval=FALSE}
# Load the tidyverse package below
?
  
# Load the data file
# This should be the witt_2018.csv file 
pong_data <- ?
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# Load the tidyverse package below
library(tidyverse)

# Load the data file
# This should be the witt_2018.csv file 
pong_data <- read_csv("data/witt_2018.csv")
```

:::

### Activity 2 - Explore `pong_data`

Remember the first critical step when you come across any new data is exploring to see how many columns you are working with, how many rows/observations there are, and what the values look like. For example, you can click on `pong_data` in the environment and scroll around it as a tab. You can also get a preview of your data by using the `glimpse()` function. 

```{r}
glimpse(pong_data)
```

If you look at that table, you can see there are 8 columns and 4608 rows. Seven of the column names are `<dbl>`, short for double, and one is `<chr>` short for character. We will need to keep the data types in mind as we wrangle the data. 

### Data types in R 

We try and balance developing your data skills in a practical way while slowly introducing some of the underlying technical points. In the last chapter, we warned about honoring data types so R knew how to handle numbers/doubles vs factors. Now we have explored a few data sets, it is time to clarify some key differences between data types in R. 

We often store data in two-dimensional tables, either called `r glossary("data frame", display = "data frames")`, tables, or `r glossary("tibble", display = "tibbles")`. There are other ways of storing data that you will discover in time but in this book, we will be using data frame or tibbles (a special type of data frame in the tidyverse). A data frame is really just a table of data with columns and rows of information. Within the cells of the data frame - a cell being where a row and a column meet - you get different types of data, including `r glossary("double")`, `r glossary("integer")`, `r glossary("character")` and `r glossary("factor")`. To summarise: 

|Type of Data | Description                                                  |
|:------------|:-------------------------------------------------------------| 
|Double       | Numbers that can take decimals                               |
|Integer      | Numbers that cannot take decimals                            |
|Character    | Tends to contain letters or be words                         |
|Factor       | Nominal (categorical). Can be words or numbers (e.g., animal or human, 1 or 2)|

Double and Integer can both be referred to as `r glossary("numeric")` data, and you will see this word from time to time. For clarity, we will use Double as a term for any number that can take a decimal (e.g. 3.14) and Integer as a term for any whole number (no decimal, e.g. 3).

Somewhat confusingly, Double data might not have decimal places in it. For instance, the value of 1 could be Double as well as Integer. However, the value of 1.1 could only be Double and never Integer. Integers cannot have decimal places. The more you work with data the more this will make sense, but it highlights the importance of looking at your data and checking what type it is as the type determines what you can do with the data.

In `pong_data`, each row (observation) represents one trial per participant and that there were 288 trials for each of the 16 participants. Most of the data is a double (i.e., numbers) and one column is a `character` (i.e., text). The columns (variables) we have in the data set are:

| Variable       |       Type                       |           Description          |
|:--------------:|:---------------------------------|:-------------------------------|
| Participant    | `r typeof(pong_data$Participant)`| participant number             |
| JudgedSpeed    | `r typeof(pong_data$JudgedSpeed)`| speed judgement (1 = fast, 0 = slow)|
| PaddleLength   | `r typeof(pong_data$PaddleLength)`| paddle length (pixels)        |
| BallSpeed      | `r typeof(pong_data$BallSpeed)`  | ball speed (2 pixels/4ms)      |
| TrialNumber    | `r typeof(pong_data$TrialNumber)`| trial number                   |
| BackgroundColor| `r typeof(pong_data$BackgroundColor)`| background display colour  |
| HitOrMiss      | `r typeof(pong_data$HitOrMiss)`  | hit ball = 1, missed ball = 0      |
| BlockNumber    | `r typeof(pong_data$BlockNumber)`| block number (out of 12 blocks)|

### Activity 3 - `select()` a range of columns {#dw2-a3}

Either by inclusion (stating all the variables you want to keep) or exclusion (stating all the variables you want to drop), create a new object named `select_dat` and select the following columns from `pong_data`:

- `Participant`

- `PaddleLength`

- `TrialNumber`

- `BackgroundColor`

- `HitOrMiss`

```{r eval=FALSE}
# select 5 variables from pong_data
select_dat <- ?
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# select 5 variables from pong_data
select_dat <- select(pong_data,
                     Participant,
                     PaddleLength,
                     TrialNumber,
                     BackgroundColor,
                     HitOrMiss)
```

:::

### Activity 4 - Reorder the variables using `select()` {#dw2-a4}

We can also use `select()` to reorder your columns, as the new data object will display the variables in the order that you entered them. 

Use `select()` to keep only the columns `Participant`, `JudgedSpeed`, `BallSpeed`, `TrialNumber`, and `HitOrMiss` from `pong_data` but this time, display them in ascending alphabetical order. Save this tibble in a new object named `reorder_dat`.

```{r eval=FALSE}
# reorder the 5 variables from pong_data
reorder_dat <- ?
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# reorder the 5 variables from pong_data
reorder_dat <- select(pong_data, # original data
                     BallSpeed,
                     HitOrMiss,
                     JudgedSpeed,
                     Participant,
                     TrialNumber)
```

:::

### Activity 5 - Reorder observations using `arrange()` {#dw2-a5}

Reorder observations in the data using the following two variables: `HitOrMiss` (putting hits (1) first) and `JudgedSpeed` (putting fast judgement () first). Store this in an object named `arrange_dat`. 

```{r eval=FALSE}
# arrange pong_data by HitOrMiss and JudgedSpeed
arrange_dat <- ?
```

Now try and answer the following questions about the data.

1. What is the trial number (`TrialNumber`) in the 1st row? `r fitb(5)`

2. What is the background colour (`BackgroundColor`) in the 10th row? `r fitb("blue")`

::: {.callout-tip collapse="true"}
#### Show me the solution
You needed to include `desc()` to change it from running smallest-to-largest to largest-to-smallest as the values are 0 and 1. You should have the following in a code chunk: 

```{r eval=FALSE}
# arrange pong_data by HitOrMiss and JudgedSpeed
arrange_dat <- arrange(pong_data, # original data
                     desc(HitOrMiss),
                     desc(JudgedSpeed))
```

:::

### Activity 6 - Modify or creating variables using `mutate()` {#dw2-a7}

Some of these values could be a little easier to understand. They are represented in the data by 0s and 1s, but it might not be immediately obvious what they mean. 

Using what you learnt in Chapter 4 about modifying existing variables, create a new variable called `JudgedSpeedLabel` by mutating the original `pong_data` object. Change the values in `JudgedSpeed` using the following labels: 

0 = Slow

1 = Fast

```{r eval=FALSE}
# mutate pong_data and recode values into a new variable
pong_data <- ?
```

::: {.callout-tip collapse="true"}
#### Show me the solution
You should have the following in a code chunk: 

```{r eval=FALSE}
# mutate pong_data and recode values into a new variable
pong_data <- mutate(pong_data, 
                    JudgedSpeedLabel = case_match(JudgedSpeed, 
                                                  0 ~ "Slow",
                                                  1 ~ "Fast"))
```

:::

## Removing or retaining observations using `filter()`

Now we have revisited key data wrangling functions from Chapter 4 to select, arrange, and mutate, it is time to add some new functions from <pkg>dplyr</pkg> to your toolkit. 

Ok great! Now, imagine you realise that there is a mistake in your dataset and that all your trial numbers are wrong. The first trial (trial number 1) was a practice so should be excluded and your experiment actually started on trial 2. Your turn! You can either do this following activity in two separate steps and create a new object each time, or you can uses pipes `%>%` and do it it one line of code. The final tibble should be stored in an object called `pong_data_renumbered`.

* Filter out all trials with the number 1 (`TrialNumber` column) from `pong_data`. 
* Then use the `mutate()` function to renumber all the remaining trial numbers, starting them at one again instead of two, overwriting the values that were in the `TrialNumber` column.

`r hide("Helpful Hint")`
```{r, echo = FALSE, results='asis'}
cat("
* Step 1. filter(`TrialNumber` does not equal 1). Remember to store this output in a variable if you are not using pipes.

* Step 2. mutate(`TrialNumber` = TrialNumber minus 1)")
```
`r unhide()`  

Great! But what about keeping and removing some of the rows with `filter()`! You may need to refer back to the different boolean operations to complete this activity!

Use `filter()` to extract all Participants in the original `pong_data` that had:

* a fast speed judgement;
* for speeds 2, 4, 5, and 7;
* but missed the ball.   

Store this remaining data in a new object called `pong_fast_miss`

`r hide("Helpful Hint")`
```{r, echo = FALSE, results='asis'}

cat("There are three parts to this filter so it is best to think about them individually and then combine them.

1. Filter all fast speed judgements (`JudgedSpeed`)

2. Filter for the speeds 2, 4, 5 and 7 (`BallSpeed`)

3. Filter for all Misses (`HitOrMiss`)

You could do this in three filters where each one uses the output of the preceding one, or remember that filter functions can take more than one argument. You may also need to use `==` instead of just `=`.")
```
`r unhide()`

<br>

```{block, type="warning"}

The filter function is very useful but if used wrongly can give you very misleading findings. This is why it is very important to always check your data after you perform an action. Let's say you are working in comparative psychology and have run a study looking at how cats, dogs and horses perceive emotion. Let's say the data is all stored in the tibble `animal_data` and there is a column called `animals` that tells you what type of animal your participant was. Imagine you wanted all the data from just cats:

`filter(animal_data, animals == "cat")`

Exactly! But what if you wanted cats and dogs?

`filter(animal_data, animals == "cat", animals == "dog")` 

Right? Wrong! This actually says "give me everything that is a cat and a dog". But nothing is a cat and a dog, that would be weird - like a dat or a cog. In fact you want everything that is either a cat **or** a dog, so you could do:

`filter(animal_data, animals == "cat"| animals == "dog")`

Or you could do:

`filter(animal_data, animals %in% c("cat", "dog"))`

You used this last approach, using `%in%`, when producing your own graph of `babynames`. It is a very helpful function so don't forget it exists!

```


## Counting observations using `count()`

## Getting summary statistics using `summarise()` and `group_by()`

Excellent! And now that we have done some wrangling we want to calculate some descriptive statistics for the data using `summarise()`. `summarise()` has a range of internal functions that make life really easy, e.g. `mean`, `sum`, `max`, `min`, etc. See the [dplyr cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) for more examples. And additional one that we will use from time-to-time is `na.rm = TRUE` which we can add when calculating descriptive statistics to say what to do if there are missing values. Missing values often appear as `NA` and the job of `na.rm` is to say whether to remove (rm) the NAs (`na.rm = TRUE`) or not (`na.rm = FALSE`). If you try to calculate values from data that have NAs, such as the mean, it would return `NA` as the result because it doesn't know how to average nothing. This dataset has no missing values but we will show you how to use it here and try to remember this argument exists, as you will use it often and it save you a lot of time!

Back to the activity. Here, using the data in `pong_data_renumbered` we will calculate:

* The total (sum) number of hits for each combination of background colour and paddle length.
* The mean number of hits for each combination of background colour and paddle length

Remember though, because we want to produce descriptive statistics by groups (background colour and paddle length), there are two steps:

* First we group the data by `BackgroundColor` and `PaddleLength` using `group_by()`.
* Then, we use `summarise()` to calculate the total and mean number of hits (`HitOrMiss`) using the grouped data

We will do this activity using pipes to reduce the amount of code we write. Remember to try and read the code out loud and to pronounce `%>%` as 'and then'. Copy and paste the below code into a new code chunk and run the code.

```{r act8-hide, echo=FALSE}
pong_data_renumbered <- filter(pong_data, 
                               TrialNumber >= 2) %>%
  mutate(TrialNumber = TrialNumber - 1)
```

```{r datasummary, eval = TRUE}
pong_data_hits <- pong_data_renumbered %>% 
  group_by(BackgroundColor, 
           PaddleLength) %>% 
  summarise(total_hits = sum(HitOrMiss, 
                             na.rm = TRUE),
            meanhits = mean(HitOrMiss, 
                            na.rm = TRUE))
```

```{block, type = "info"}
Remember, if you get what looks like an error that says "`summarise()` has grouped output by 'BackgroundColor'. You can override using the `.groups` argument.", don't worry, this isn't an error it's just the code telling you how the final object is grouped.
```

* View `pong_data_hits` and answer the following questions to see if you have completed the task correctly.

```{r mcq-ans1, echo = FALSE}
act8_correct <- pong_data_hits %>% 
  filter(BackgroundColor == "blue", 
         PaddleLength == 50) %>% 
  pull(total_hits)
act8_false1 <- pong_data_hits %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 50) %>% 
  pull(total_hits)
act8_false2 <- pong_data_hits %>% 
  filter(BackgroundColor == "blue", 
         PaddleLength == 250) %>% 
  pull(total_hits)
act8_false3 <- pong_data_hits %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 250) %>%
  pull(total_hits)
```

* What was the total number of hits made with the small paddle (50) and the blue colour background? `r longmcq(sample(c(answer = act8_correct,act8_false3,act8_false2,act8_false1)))`

```{r mcq-ans2, echo = FALSE}
act8_correct <- pong_data_hits %>% 
  filter(BackgroundColor == "blue", 
         PaddleLength == 50) %>% 
  pull(meanhits) %>%
  round(3)
act8_false1 <- pong_data_hits %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 50) %>% 
  pull(meanhits) %>%
  round(3)
act8_false2 <- pong_data_hits %>% 
  filter(BackgroundColor == "blue", 
         PaddleLength == 250) %>% 
  pull(meanhits) %>%
  round(3)
act8_false3 <- pong_data_hits %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 250) %>%
  pull(meanhits) %>%
  round(3)
```

* To three decimal places, what was the mean number of hits made with the small paddle (50) and the blue colour background? `r longmcq(sample(c(answer = act8_correct,act8_false3,act8_false2,act8_false1)))`

**Note:**

* The name of the column within `pong_data_hits` is `total_hits`; this is what you called it in the above code. You could have called it anything you wanted but always try to use something sensible.
* Make sure to call your variables something you (and anyone looking at your code) will understand and recognize later (i.e. not variable1, variable2, variable3. etc.), and avoid spaces (use_underscores_never_spaces). 

## Combining functions using the pipe

## Ungrouping, counting, pipes - quick notes!

You have done some superb work today! Congratulations. You should be really proud of yourself. Before ending we just want to show a couple more new functions and approaches that will help in future activities.

### Counting data {#dw2-a9}

First we want to look at different ways of counting your observations. Often it is helpful to know how many observations you have, either in total, or broken down by groups. This can help you spot if something has gone wrong in a calculation, for example, if you've done something with the code and your mean or median is only being calculated using a subset of the values you intended.

There are two ways of counting the number of observations. The first uses `summarise()` and the function `n()` within the `summarise()`. For example, the below code is the same as the previous activity, but with an extra line that will add a column called `n` to the table that contains the number of observations in each group. This is useful for when you want to add a column of counts to a table of other descriptive statistics. 

* **Note:** the function is `n()` and takes no arguments it is just left blank as shown, `n()`.  However, as in other functions, the `n` prior to the `=` could be called anything you want the column to be called, e.g. `n = n()` or `number = n()` would do the same but just give different names to the column.

```{r showing-n, message = FALSE}
pong_count <- pong_data_renumbered %>% 
  group_by(BackgroundColor, 
           PaddleLength) %>% 
  summarise(total_hits = sum(HitOrMiss, 
                             na.rm = TRUE),
            meanhits = mean(HitOrMiss, 
                            na.rm = TRUE),
            n = n())
```

However, if you're just interested in counts rather than also calculating descriptives, this above method is a bit clunky. Instead, we can use the function `count()` which is specifically designed to count observations and doesn't require the use of `summarise()` or `group_by()`.

To count the total number of observations in the dataset for example we would do:

```{r count1, eval = FALSE}
pong_data %>% # take pong_data
  count() # and then count the observations in it
```

And it would give the answer of:

```{r count2, echo = FALSE}
pong_data %>% count()
```

Alternatively, to count the number of observations in each level of a variable you could do:

```{r count3, eval = FALSE}
pong_data %>%
  count(BackgroundColor)
```

And it would give the answer of:

```{r count4, echo = FALSE}
pong_data %>%
  count(BackgroundColor)
```

Which method you use will depend on whether you want to add the counts to a table of other descriptives, but both functions are useful to know.

### Ungrouping data {#dw2-ungroup}

After grouping data together using the `group_by()` function and then performing a task on it, e.g. `filter()`, it can be very good practice to ungroup the data before performing another function - by piping it into the `ungroup()` function - this is related to what the warnings about `summarise()` mean as they are changing the groupings so removing all groupings can be good to do. Forgetting to ungroup the dataset won't always affect further processing, but can really mess up other things. Again just a good reminder to always check the data you are getting out of a function a) makes sense and b) is what you expect.

This is an example of how you might use the function:

```{r ungroup1, eval = FALSE}
pong_data_ungroup <- pong_data %>%
  group_by(BackgroundColor, 
           PaddleLength) %>%
  summarise(total_hits = sum(HitOrMiss)) %>%
  ungroup
```

### Recapping Pipes (**`%>%`**) {#dw2-pipes}  

And finally today we just want to throw in a quick recap on `r glossary("pipe", display = "pipes")`. We have used pipes a little above but you might still not have got the hang of it so reading through this will help a little. Remember where pipes become most useful is when we **string a series of functions together**, rather than using them as separate steps and having to save the data each time under a new variable name and getting ourselves all confused. In non-piped code we have to create a new object each time, for example, `data`, `data_filtered`, `data_arranged`, `data_grouped`, `data_summarised` just to get to the final one we actually want.  This creates a lot of variables and tibbles in our environment and can make everything unclear, difficult to follow, and eventually slow down our computer. Piped code however uses one variable name, saving space in the environment, and is clear and easy to read. With pipes we skip unnecessary steps and avoid cluttering our environment.  

Here is an example of code that doesn't use pipes to find how many hits there were with the large paddle length and the red background:

* First we group the data accordingly, storing it in `pong_data_group`
* And then we summarise it, storing the answer in `total_hits`
* And finally we filter just the red, large paddle hits

```{r datasummary-nopipe, eval = FALSE}

pong_data_group <- group_by(pong_data, 
                            BackgroundColor, 
                            PaddleLength)

pong_data_hits <- summarise(pong_data_group, 
                            total_hits = sum(HitOrMiss))

pong_data_hits_red_large <- filter(pong_data_hits, 
                                   BackgroundColor == "red", 
                                   PaddleLength == 250)
```

Alternatively we can make our code even more efficient, using less code, by stringing our sequence of functions together using pipes. This would look like:

```{r datasummary-pipes, eval = FALSE}
pong_data_hits_red_large <- pong_data %>% 
  group_by(BackgroundColor, 
           PaddleLength) %>% 
  summarise(total_hits = sum(HitOrMiss)) %>% 
  filter(BackgroundColor == "red", 
         PaddleLength == 250) 
```

So the code becomes easier to read as you remember the data goes into one function "and then" into another, "and then" into another, and so on. 

It is also worth remembering that whilst pipes and code can be written in a single line, but it is much easier to see what the pipe is doing if each function takes its own line. You just have to remember that every time you add a function to the pipeline, add a `%>%` first and **note that when using separate lines for each function, the `%>%` must appear at the end of the line and not the start of the next line**. Compare the two examples below. The first won't work but the second will because the second puts the pipes at the end of the line where they need to be!

``` {r pipes3, eval = FALSE}
# Piped version that won't work 
data_arrange <- pong_data 
                %>% filter(PaddleLength == "50")
                %>% arrange(BallSpeed) 

# Piped version that will work 
data_arrange <- pong_data %>%
                filter(PaddleLength == "50") %>%
                arrange(BallSpeed) 
```

## Test yourself

To end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter. 

### Knowledge check

1. What type of data would these most likely be:

* Male = `r mcq(c(answer = "Character","Numeric","Integer"))`

* 7.15 = `r mcq(c("Character",answer = "Double","Integer"))`

* 137 = `r mcq(c("Character","Double",answer = "Integer"))`

`r hide("Explain these answers")`
```{r, echo = FALSE, results='asis'}
cat("
There is a lot of different types of data and as well as different types of levels of measurements and it can get very confusing. It's important to try to remember which is which because you can only do certain types of analyses on certain types of data and certain types of measurements. For instance, you can't take the average of Characters just like you can't take the average of Categorical data. Likewise, you can do any maths on Double data, just like you can on Interval and Ratio data. Integer data is funny in that sometimes it is Ordinal and sometimes it is Interval, sometimes you should take the median, sometimes you should take the mean. The main point is to always know what type of data you are using and to think about what you can and cannot do with them.

* Note that the last answer, 137, could also be double as it isn't clear if it could take a decimal or not. 
")
```
`r unhide()`

<br>

2. Which of the Wickham Six would you use to sort columns from smallest to largest: `r longmcq(c("select","filter","mutate",answer ="arrange","group_by","summarise"))`
3. Which of the Wickham Six would you use to calculate the mean of a column: `r longmcq(c("select","filter","mutate","arrange","group_by",answer ="summarise"))`
4. Which of the Wickham Six would you use to remove certain observations - e.g. remove all males: `r longmcq(c("select",answer = "filter","mutate","arrange","group_by","summarise"))` 
5. What does this line of code say? `data %>% filter() %>% group_by() %>% summarise()`: `r longmcq(c("take the data and then group it and then filter it and then summarise it", answer = "take the data and then filter it and then group it and then summarise it", "take the data and then summarise it and then filter it and then group it","take the data and then group it and then summarise it and then filter it"))`  

### Error mode

The following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using the functions `inner_join()`, `select()`, and `mutate()`. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently. 

Create and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load `tidyverse` and the two data files: 

### Debugging tips {#dw2-debug}

There are no debugging challenges today as we have done a lot of work but here are some tips to keep in mind.

* Remember to run the library and not just write the code
* Make sure you have spelt the data file name **exactly** as it is shown. Spaces and everything. Do not change the name of the csv file, fix your code instead. If you have a different name for your file than someone else then your code is not reproducible.
* Remember when uploading data we use `read_csv()` which has an underscore, whereas the data file itself will have a dot in its name, `filename.csv`. 
* Check that the datafile is actually in the folder you have set as your working directory. 
* Remember to start a new session each time you start a new analysis - the more functions and packages you use the great a chance of conflicting functions. 
* Watch the spelling of functions and remember to put the data first. Often people forget to include the data as they are focussing on what they want to do.
* Always look at the output of your functions as you build the code. Often code runs but it doesn't do what you think it is doing because you wrote the code wrong. Code only does what you tell it to do!
* When using pipes, remember that you only need the data once, at the start.
* If separating pipes across different lines, remember the line ends with the pipe, it does not start with the pipe.
* And lastly, remember that only the data changes, the skills stay the same. Always look back to when you had the code working and go from there.

### Activity 6 {#dw2-a6sol}

* Remembering that filters can take more than one argument then the below code would filter for data where:

* JudgedSpeed is 1 AND
* BallSpeed is either 2, 4, 5, or 7, AND
* HitOrMiss is 0.

```{r filt1, eval = TRUE}
pong_fast_miss <- filter(pong_data, 
                         JudgedSpeed == 1, 
                         BallSpeed %in% c("2", "4", "5", "7"), 
                         HitOrMiss == 0)
```
 
### Activity 7 {#dw2-a7sol}

If you didn't use pipes then the following code would be appropriate:

* First you filter. And remember that you can call the first object `pong_data_filt` anything that makes sense to you and others.
* Then in a separate step you mutate.

```{r act7-1, eval = TRUE}
pong_data_filt <- filter(pong_data, 
                         TrialNumber >= 2) 

pong_data_renumbered <- mutate(pong_data_filt, 
                               TrialNumber = TrialNumber - 1)
```

And if you used pipes this would be the solution:

* Remember you include the data once, and the pipes end the line, they do not start the line.

```{r act7-2, eval = TRUE}
pong_data_renumbered <- filter(pong_data, 
                               TrialNumber >= 2) %>%
  mutate(TrialNumber = TrialNumber - 1)
```

which could also be written as below - which some find better to remember the data goes in first and only once:

```{r act7-3, eval = TRUE}
pong_data_renumbered <- pong_data %>%
  filter(TrialNumber >= 2) %>%
  mutate(TrialNumber = TrialNumber - 1)
```

## Words from this Chapter

Below you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the [PsyTeachR Glossary](https://psyteachr.github.io/glossary/){target="_blank"}. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.

```{r gloss, echo=FALSE, results='asis'}
glossary_table()
```

## End of chapter

That is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!

Brilliant work again! We have now learned a number of functions and verbs that you will need as you progress through this book.  You will use them in the next chapter so be sure to go over these and try them out to make yourself more comfortable with them.  If you have any questions please post them on Teams. **Happy Wrangling!**



